{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test des fonctions de reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import gym\n",
    "\n",
    "\n",
    "#from cartpole import CartPoleEnv\n",
    "#env = CartPoleEnv()\n",
    "env = gym.make('CartPole-v1')\n",
    "env.reset()\n",
    "episodes = 20\n",
    "final = []\n",
    "for episode in range(episodes):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total = 0\n",
    "    while not done:\n",
    "        # Sample random actions\n",
    "        action = env.action_space.sample()\n",
    "        # Take action and extract results\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        # Update reward\n",
    "        total += reward\n",
    "        if done:\n",
    "            break\n",
    "    # Add to the final reward\n",
    "    final.append(total)\n",
    "    print(final)\n",
    "env.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test du .render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "for _ in range(100):\n",
    "    #env.render()\n",
    "    env.step(env.action_space.sample()) # take a random action\n",
    "env.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretization du cartpole (sers plus actuellement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\n",
    "one_degree = 0.0174532\n",
    "six_degrees = 0.1047192\n",
    "twelve_degrees = 0.2094384\n",
    "fifty_degrees = 0.87266\n",
    "\n",
    "def get_box(x,x_dot,theta,theta_dot):\n",
    "  if (x < -0.8): x = 0;\n",
    "  elif (x < 0.8): x = 1;\n",
    "  else: x = 2;\n",
    "\n",
    "  if (x_dot < -0.5): x_dot = 0;\n",
    "  elif (x_dot < 0.5): x_dot = 1;\n",
    "  else: x_dot = 2;\n",
    "\n",
    "  if (theta < -six_degrees): theta = 0\n",
    "  elif (theta < -one_degree): theta = 1\n",
    "  elif (theta < 0): theta = 2\n",
    "  elif (theta < one_degree): theta = 3\n",
    "  elif (theta < six_degrees): theta = 4\n",
    "  else: theta = 5\n",
    "\n",
    "  if (theta_dot < -fifty_degrees): theta_dot = 0;\n",
    "  elif (theta_dot < fifty_degrees):  box = 1;\n",
    "  else: box = 2;\n",
    "\n",
    "  return(box);\n",
    "\"\"\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN class et application sur cartpole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import gym\n",
    "import random\n",
    "\n",
    "GAMMA = 0.95\n",
    "LEARNING_RATE = 0.001\n",
    "MEMORY_SIZE = 1000000\n",
    "BATCH_SIZE = 20\n",
    "EXPLORATION_MAX = 1.0\n",
    "EXPLORATION_MIN = 0.01\n",
    "EXPLORATION_DECAY = 0.998\n",
    "\n",
    "class DQNSolver:\n",
    "\n",
    "    def __init__(self, observation_space, action_space):\n",
    "        self.exploration_rate = EXPLORATION_MAX\n",
    "\n",
    "        self.action_space = action_space\n",
    "        self.memory = deque(maxlen=MEMORY_SIZE)\n",
    "\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(24, input_shape=(observation_space,), activation=\"relu\"))\n",
    "        self.model.add(Dense(24, activation=\"relu\"))\n",
    "        self.model.add(Dense(self.action_space, activation=\"linear\"))\n",
    "        self.model.compile(loss=\"mse\", optimizer=Adam(lr=LEARNING_RATE))\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() < self.exploration_rate:\n",
    "            return random.randrange(self.action_space)\n",
    "        q_values = self.model.predict(state)\n",
    "        return np.argmax(q_values[0])\n",
    "\n",
    "    def experience_replay(self):\n",
    "        if len(self.memory) < BATCH_SIZE:\n",
    "            return\n",
    "        batch = random.sample(self.memory, BATCH_SIZE)\n",
    "        for state, action, reward, state_next, terminal in batch:\n",
    "            q_update = reward\n",
    "            if not terminal:\n",
    "                q_update = (reward + GAMMA * np.amax(self.model.predict(state_next)[0]))\n",
    "            q_values = self.model.predict(state)\n",
    "            q_values[0][action] = q_update\n",
    "            self.model.fit(state, q_values, verbose=0)\n",
    "        self.exploration_rate *= EXPLORATION_DECAY\n",
    "        self.exploration_rate = max(EXPLORATION_MIN, self.exploration_rate)\n",
    "        \n",
    "    \n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartpole(EPISODES):\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    observation_space = env.observation_space.shape[0]\n",
    "    action_space = env.action_space.n\n",
    "    dqn_solver = DQNSolver(observation_space, action_space)\n",
    "\n",
    "    \n",
    "    final = []\n",
    "    for e in range(EPISODES):\n",
    "        \n",
    "        state = env.reset()\n",
    "        state = np.reshape(state, [1, observation_space])\n",
    "        step = 0\n",
    "        while True:\n",
    "            step += 1\n",
    "            #env.render()\n",
    "            action = dqn_solver.act(state)\n",
    "            state_next, reward, terminal, info = env.step(action)\n",
    "            reward = reward if not terminal else -reward\n",
    "            state_next = np.reshape(state_next, [1, observation_space])\n",
    "            dqn_solver.remember(state, action, reward, state_next, terminal)\n",
    "            state = state_next\n",
    "            if terminal:\n",
    "                print(\"Run: \" + str(e) + \", exploration: \" + str(dqn_solver.exploration_rate) + \", score: \" + str(step))\n",
    "                break\n",
    "            dqn_solver.experience_replay()\n",
    "        final.append(step)\n",
    "            \n",
    "    dqn_solver.save(\"./cartpole-dqn.h5\")\n",
    "    #print(dqn_solver.model.layers[0].get_weights()[0])\n",
    "    return final\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0, exploration: 1.0, score: 12\n",
      "Run: 1, exploration: 0.9801790433519495, score: 18\n",
      "Run: 2, exploration: 0.9398245380496356, score: 22\n",
      "Run: 3, exploration: 0.8727237754706968, score: 38\n",
      "Run: 4, exploration: 0.8486026537619556, score: 15\n",
      "Run: 5, exploration: 0.7991358687971188, score: 31\n",
      "Run: 6, exploration: 0.7450571198597635, score: 36\n",
      "Run: 7, exploration: 0.7215696031781899, score: 17\n",
      "Run: 8, exploration: 0.684971186740455, score: 27\n",
      "Run: 9, exploration: 0.6013917789643461, score: 66\n",
      "[[-0.12076794 -0.19908799  0.07603423 -0.49543872 -0.09274016  0.1370585\n",
      "   0.7004281   0.07828736 -0.47499463  0.12281825  0.22132458 -0.38151222\n",
      "  -0.17587084  0.2372544  -0.17899603 -0.11059985 -0.3298313  -0.61834943\n",
      "  -0.44205296 -0.12091755 -0.6845082  -0.32522842  0.28774393 -0.06576917]\n",
      " [-0.37843376 -0.32927975 -0.55105555 -0.0254655   0.36433473 -0.19687702\n",
      "  -0.3337792  -0.13071582  0.02683747  0.04569326  0.02263121  0.0933734\n",
      "   0.08291382  0.04233343  0.05198677 -0.3471207  -0.16834657  0.24518853\n",
      "   0.28122717  0.431316   -0.33008614  0.08234873 -0.13280767  0.00562759]\n",
      " [ 0.39939523 -0.06704698 -0.38660663  0.66444    -0.1658256  -0.44588196\n",
      "  -0.46660495  0.39991555  0.18300596 -0.10504778 -0.03708135 -0.09935609\n",
      "   0.48679912  0.58567625  0.27197576 -0.26267537 -0.26120037 -0.1458908\n",
      "  -0.07054454 -0.27405837  0.6905025   0.09835091 -0.1944507   0.24769594]\n",
      " [-0.06191836 -0.12754934 -0.48010767  0.15049013  0.21343362  0.1623399\n",
      "  -0.282071   -0.0132969   0.2722711  -0.14641188  0.27342606 -0.00435821\n",
      "   0.16475946 -0.21084312  0.00802329  0.19587281 -0.19754846 -0.03378206\n",
      "   0.09200515 -0.4594236   0.28399906  0.38990435  0.08516352 -0.20027559]]\n"
     ]
    }
   ],
   "source": [
    "results = cartpole(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(results)\n",
    "plt.savefig('score.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essai réussi de reload l'agent :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score atteint  129\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import time\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "observation_space = env.observation_space.shape[0]\n",
    "action_space = env.action_space.n\n",
    "dqn_solver = DQNSolver(observation_space, action_space)\n",
    "\n",
    "dqn_solver.load(\"./cartpole-dqn.h5\")\n",
    "state = env.reset()\n",
    "state = np.reshape(state, [1, observation_space])\n",
    "\n",
    "for e in range(800):\n",
    "    #env.render()\n",
    "    action = np.argmax(dqn_solver.model.predict(state)[0])\n",
    "    state_next, reward, terminal, info = env.step(action)\n",
    "    state_next = np.reshape(state_next, [1, observation_space])\n",
    "    state = state_next\n",
    "    #time.sleep(0.5)\n",
    "    if terminal:\n",
    "        print(\"Score atteint \",e)\n",
    "        print(\"done\")\n",
    "        break\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maintenant deep Learning plus compliqué (DDQ avec image input via atari)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from statistics import mean\n",
    "from game_models.base_game_model import BaseGameModel\n",
    "from convolutional_neural_network import ConvolutionalNeuralNetwork\n",
    "\n",
    "GAMMA = 0.99\n",
    "MEMORY_SIZE = 900000\n",
    "BATCH_SIZE = 32\n",
    "TRAINING_FREQUENCY = 4\n",
    "TARGET_NETWORK_UPDATE_FREQUENCY = 40000\n",
    "MODEL_PERSISTENCE_UPDATE_FREQUENCY = 10000\n",
    "REPLAY_START_SIZE = 50000\n",
    "\n",
    "EXPLORATION_MAX = 1.0\n",
    "EXPLORATION_MIN = 0.1\n",
    "EXPLORATION_TEST = 0.02\n",
    "EXPLORATION_STEPS = 850000\n",
    "EXPLORATION_DECAY = (EXPLORATION_MAX-EXPLORATION_MIN)/EXPLORATION_STEPS\n",
    "\n",
    "\n",
    "class DDQNGameModel():\n",
    "\n",
    "    def __init__(self, game_name, mode_name, input_shape, action_space, logger_path, model_path):\n",
    "        self.action_space = action_space\n",
    "        self.input_shape = input_shape\n",
    "        self.model_path = model_path\n",
    "        self.ddqn = ConvolutionalNeuralNetwork(self.input_shape, action_space).model\n",
    "        if os.path.isfile(self.model_path):\n",
    "            self.ddqn.load_weights(self.model_path)\n",
    "\n",
    "    def _save_model(self):\n",
    "        self.ddqn.save_weights(self.model_path)\n",
    "\n",
    "\n",
    "class DDQNSolver(DDQNGameModel):\n",
    "\n",
    "    def __init__(self, game_name, input_shape, action_space):\n",
    "        testing_model_path = \"./output/neural_nets/\" + game_name + \"/ddqn/testing/model.h5\"\n",
    "        assert os.path.exists(os.path.dirname(testing_model_path)), \"No testing model in: \" + str(testing_model_path)\n",
    "        DDQNGameModel.__init__(self,\n",
    "                               game_name,\n",
    "                               \"DDQN testing\",\n",
    "                               input_shape,\n",
    "                               action_space,\n",
    "                               \"./output/logs/\" + game_name + \"/ddqn/testing/\" + self._get_date() + \"/\",\n",
    "                               testing_model_path)\n",
    "\n",
    "    def move(self, state):\n",
    "        if np.random.rand() < EXPLORATION_TEST:\n",
    "            return random.randrange(self.action_space)\n",
    "        q_values = self.ddqn.predict(np.expand_dims(np.asarray(state).astype(np.float64), axis=0), batch_size=1)\n",
    "        return np.argmax(q_values[0])\n",
    "\n",
    "\n",
    "class DDQNTrainer(DDQNGameModel):\n",
    "\n",
    "    def __init__(self, game_name, input_shape, action_space):\n",
    "        DDQNGameModel.__init__(self,\n",
    "                               game_name,\n",
    "                               \"DDQN training\",\n",
    "                               input_shape,\n",
    "                               action_space,\n",
    "                               \"./output/logs/\" + game_name + \"/ddqn/training/\" + self._get_date() + \"/\",\n",
    "                               \"./output/neural_nets/\" + game_name + \"/ddqn/\" + self._get_date() + \"/model.h5\")\n",
    "\n",
    "        if os.path.exists(os.path.dirname(self.model_path)):\n",
    "            shutil.rmtree(os.path.dirname(self.model_path), ignore_errors=True)\n",
    "        os.makedirs(os.path.dirname(self.model_path))\n",
    "\n",
    "        self.ddqn_target = ConvolutionalNeuralNetwork(self.input_shape, action_space).model\n",
    "        self._reset_target_network()\n",
    "        self.epsilon = EXPLORATION_MAX\n",
    "        self.memory = []\n",
    "\n",
    "    def move(self, state):\n",
    "        if np.random.rand() < self.epsilon or len(self.memory) < REPLAY_START_SIZE:\n",
    "            return random.randrange(self.action_space)\n",
    "        q_values = self.ddqn.predict(np.expand_dims(np.asarray(state).astype(np.float64), axis=0), batch_size=1)\n",
    "        return np.argmax(q_values[0])\n",
    "\n",
    "    def remember(self, current_state, action, reward, next_state, terminal):\n",
    "        self.memory.append({\"current_state\": current_state,\n",
    "                            \"action\": action,\n",
    "                            \"reward\": reward,\n",
    "                            \"next_state\": next_state,\n",
    "                            \"terminal\": terminal})\n",
    "        if len(self.memory) > MEMORY_SIZE:\n",
    "            self.memory.pop(0)\n",
    "\n",
    "    def step_update(self, total_step):\n",
    "        if len(self.memory) < REPLAY_START_SIZE:\n",
    "            return\n",
    "\n",
    "        if total_step % TRAINING_FREQUENCY == 0:\n",
    "            loss, accuracy, average_max_q = self._train()\n",
    "            self.logger.add_loss(loss)\n",
    "            self.logger.add_accuracy(accuracy)\n",
    "            self.logger.add_q(average_max_q)\n",
    "\n",
    "        self._update_epsilon()\n",
    "\n",
    "        if total_step % MODEL_PERSISTENCE_UPDATE_FREQUENCY == 0:\n",
    "            self._save_model()\n",
    "\n",
    "        if total_step % TARGET_NETWORK_UPDATE_FREQUENCY == 0:\n",
    "            self._reset_target_network()\n",
    "            print('{{\"metric\": \"epsilon\", \"value\": {}}}'.format(self.epsilon))\n",
    "            print('{{\"metric\": \"total_step\", \"value\": {}}}'.format(total_step))\n",
    "\n",
    "    def _train(self):\n",
    "        batch = np.asarray(random.sample(self.memory, BATCH_SIZE))\n",
    "        if len(batch) < BATCH_SIZE:\n",
    "            return\n",
    "\n",
    "        current_states = []\n",
    "        q_values = []\n",
    "        max_q_values = []\n",
    "\n",
    "        for entry in batch:\n",
    "            current_state = np.expand_dims(np.asarray(entry[\"current_state\"]).astype(np.float64), axis=0)\n",
    "            current_states.append(current_state)\n",
    "            next_state = np.expand_dims(np.asarray(entry[\"next_state\"]).astype(np.float64), axis=0)\n",
    "            next_state_prediction = self.ddqn_target.predict(next_state).ravel()\n",
    "            next_q_value = np.max(next_state_prediction)\n",
    "            q = list(self.ddqn.predict(current_state)[0])\n",
    "            if entry[\"terminal\"]:\n",
    "                q[entry[\"action\"]] = entry[\"reward\"]\n",
    "            else:\n",
    "                q[entry[\"action\"]] = entry[\"reward\"] + GAMMA * next_q_value\n",
    "            q_values.append(q)\n",
    "            max_q_values.append(np.max(q))\n",
    "\n",
    "        fit = self.ddqn.fit(np.asarray(current_states).squeeze(),\n",
    "                            np.asarray(q_values).squeeze(),\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            verbose=0)\n",
    "        loss = fit.history[\"loss\"][0]\n",
    "        accuracy = fit.history[\"acc\"][0]\n",
    "        return loss, accuracy, mean(max_q_values)\n",
    "\n",
    "    def _update_epsilon(self):\n",
    "        self.epsilon -= EXPLORATION_DECAY\n",
    "        self.epsilon = max(EXPLORATION_MIN, self.epsilon)\n",
    "\n",
    "    def _reset_target_network(self):\n",
    "        self.ddqn_target.set_weights(self.ddqn.get_weights())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
