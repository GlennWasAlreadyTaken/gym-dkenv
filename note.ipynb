{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test des fonctions de reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import gym\n",
    "\n",
    "\n",
    "#from cartpole import CartPoleEnv\n",
    "#env = CartPoleEnv()\n",
    "env = gym.make('CartPole-v1')\n",
    "env.reset()\n",
    "episodes = 20\n",
    "final = []\n",
    "for episode in range(episodes):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total = 0\n",
    "    while not done:\n",
    "        # Sample random actions\n",
    "        action = env.action_space.sample()\n",
    "        # Take action and extract results\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        # Update reward\n",
    "        total += reward\n",
    "        if done:\n",
    "            break\n",
    "    # Add to the final reward\n",
    "    final.append(total)\n",
    "    print(final)\n",
    "env.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test du .render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "for _ in range(100):\n",
    "    #env.render()\n",
    "    env.step(env.action_space.sample()) # take a random action\n",
    "env.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretization du cartpole (sers plus actuellement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\n",
    "one_degree = 0.0174532\n",
    "six_degrees = 0.1047192\n",
    "twelve_degrees = 0.2094384\n",
    "fifty_degrees = 0.87266\n",
    "\n",
    "def get_box(x,x_dot,theta,theta_dot):\n",
    "  if (x < -0.8): x = 0;\n",
    "  elif (x < 0.8): x = 1;\n",
    "  else: x = 2;\n",
    "\n",
    "  if (x_dot < -0.5): x_dot = 0;\n",
    "  elif (x_dot < 0.5): x_dot = 1;\n",
    "  else: x_dot = 2;\n",
    "\n",
    "  if (theta < -six_degrees): theta = 0\n",
    "  elif (theta < -one_degree): theta = 1\n",
    "  elif (theta < 0): theta = 2\n",
    "  elif (theta < one_degree): theta = 3\n",
    "  elif (theta < six_degrees): theta = 4\n",
    "  else: theta = 5\n",
    "\n",
    "  if (theta_dot < -fifty_degrees): theta_dot = 0;\n",
    "  elif (theta_dot < fifty_degrees):  box = 1;\n",
    "  else: box = 2;\n",
    "\n",
    "  return(box);\n",
    "\"\"\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN class et application sur cartpole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import gym\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GAMMA = 0.95\n",
    "LEARNING_RATE = 0.001\n",
    "MEMORY_SIZE = 1000000\n",
    "BATCH_SIZE = 20\n",
    "EXPLORATION_MAX = 1.0\n",
    "EXPLORATION_MIN = 0.01\n",
    "EXPLORATION_DECAY = 0.998\n",
    "\n",
    "class DQNSolver:\n",
    "\n",
    "    def __init__(self, observation_space, action_space):\n",
    "        self.exploration_rate = EXPLORATION_MAX\n",
    "\n",
    "        self.action_space = action_space\n",
    "        self.memory = deque(maxlen=MEMORY_SIZE)\n",
    "\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(24, input_shape=(observation_space,), activation=\"relu\"))\n",
    "        self.model.add(Dense(24, activation=\"relu\"))\n",
    "        self.model.add(Dense(self.action_space, activation=\"linear\"))\n",
    "        self.model.compile(loss=\"mse\", optimizer=Adam(lr=LEARNING_RATE))\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() < self.exploration_rate:\n",
    "            return random.randrange(self.action_space)\n",
    "        q_values = self.model.predict(state)\n",
    "        return np.argmax(q_values[0])\n",
    "\n",
    "    def experience_replay(self):\n",
    "        if len(self.memory) < BATCH_SIZE:\n",
    "            return\n",
    "        batch = random.sample(self.memory, BATCH_SIZE)\n",
    "        for state, action, reward, state_next, terminal in batch:\n",
    "            q_update = reward\n",
    "            if not terminal:\n",
    "                q_update = (reward + GAMMA * np.amax(self.model.predict(state_next)[0]))\n",
    "            q_values = self.model.predict(state)\n",
    "            q_values[0][action] = q_update\n",
    "            self.model.fit(state, q_values, verbose=0)\n",
    "        self.exploration_rate *= EXPLORATION_DECAY\n",
    "        self.exploration_rate = max(EXPLORATION_MIN, self.exploration_rate)\n",
    "        \n",
    "    \n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartpole(EPISODES):\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    observation_space = env.observation_space.shape[0]\n",
    "    action_space = env.action_space.n\n",
    "    dqn_solver = DQNSolver(observation_space, action_space)\n",
    "\n",
    "    \n",
    "    final = []\n",
    "    for e in range(EPISODES):\n",
    "        \n",
    "        state = env.reset()\n",
    "        state = np.reshape(state, [1, observation_space])\n",
    "        step = 0\n",
    "        while True:\n",
    "            step += 1\n",
    "            #env.render()\n",
    "            action = dqn_solver.act(state)\n",
    "            state_next, reward, terminal, info = env.step(action)\n",
    "            reward = reward if not terminal else -reward\n",
    "            state_next = np.reshape(state_next, [1, observation_space])\n",
    "            dqn_solver.remember(state, action, reward, state_next, terminal)\n",
    "            state = state_next\n",
    "            if terminal:\n",
    "                print(\"Run: \" + str(e) + \", exploration: \" + str(dqn_solver.exploration_rate) + \", score: \" + str(step))\n",
    "                break\n",
    "            dqn_solver.experience_replay()\n",
    "        final.append(step)\n",
    "            \n",
    "    dqn_solver.save(\"./cartpole-dqn.h5\")\n",
    "    #print(dqn_solver.model.layers[0].get_weights()[0])\n",
    "    return final\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0, exploration: 1.0, score: 12\n",
      "Run: 1, exploration: 0.9801790433519495, score: 18\n",
      "Run: 2, exploration: 0.9398245380496356, score: 22\n",
      "Run: 3, exploration: 0.8727237754706968, score: 38\n",
      "Run: 4, exploration: 0.8486026537619556, score: 15\n",
      "Run: 5, exploration: 0.7991358687971188, score: 31\n",
      "Run: 6, exploration: 0.7450571198597635, score: 36\n",
      "Run: 7, exploration: 0.7215696031781899, score: 17\n",
      "Run: 8, exploration: 0.684971186740455, score: 27\n",
      "Run: 9, exploration: 0.6013917789643461, score: 66\n",
      "[[-0.12076794 -0.19908799  0.07603423 -0.49543872 -0.09274016  0.1370585\n",
      "   0.7004281   0.07828736 -0.47499463  0.12281825  0.22132458 -0.38151222\n",
      "  -0.17587084  0.2372544  -0.17899603 -0.11059985 -0.3298313  -0.61834943\n",
      "  -0.44205296 -0.12091755 -0.6845082  -0.32522842  0.28774393 -0.06576917]\n",
      " [-0.37843376 -0.32927975 -0.55105555 -0.0254655   0.36433473 -0.19687702\n",
      "  -0.3337792  -0.13071582  0.02683747  0.04569326  0.02263121  0.0933734\n",
      "   0.08291382  0.04233343  0.05198677 -0.3471207  -0.16834657  0.24518853\n",
      "   0.28122717  0.431316   -0.33008614  0.08234873 -0.13280767  0.00562759]\n",
      " [ 0.39939523 -0.06704698 -0.38660663  0.66444    -0.1658256  -0.44588196\n",
      "  -0.46660495  0.39991555  0.18300596 -0.10504778 -0.03708135 -0.09935609\n",
      "   0.48679912  0.58567625  0.27197576 -0.26267537 -0.26120037 -0.1458908\n",
      "  -0.07054454 -0.27405837  0.6905025   0.09835091 -0.1944507   0.24769594]\n",
      " [-0.06191836 -0.12754934 -0.48010767  0.15049013  0.21343362  0.1623399\n",
      "  -0.282071   -0.0132969   0.2722711  -0.14641188  0.27342606 -0.00435821\n",
      "   0.16475946 -0.21084312  0.00802329  0.19587281 -0.19754846 -0.03378206\n",
      "   0.09200515 -0.4594236   0.28399906  0.38990435  0.08516352 -0.20027559]]\n"
     ]
    }
   ],
   "source": [
    "results = cartpole(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(results)\n",
    "plt.savefig('score.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essai réussi de reload l'agent :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score atteint  129\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import time\n",
    "env = gym.make('CartPole-v0')\n",
    "\n",
    "observation_space = env.observation_space.shape[0]\n",
    "action_space = env.action_space.n\n",
    "dqn_solver = DQNSolver(observation_space, action_space)\n",
    "\n",
    "dqn_solver.load(\"./cartpole-dqn.h5\")\n",
    "state = env.reset()\n",
    "state = np.reshape(state, [1, observation_space])\n",
    "\n",
    "for e in range(800):\n",
    "    #env.render()\n",
    "    action = np.argmax(dqn_solver.model.predict(state)[0])\n",
    "    state_next, reward, terminal, info = env.step(action)\n",
    "    state_next = np.reshape(state_next, [1, observation_space])\n",
    "    state = state_next\n",
    "    #time.sleep(0.5)\n",
    "    if terminal:\n",
    "        print(\"Score atteint \",e)\n",
    "        print(\"done\")\n",
    "        break\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maintenant deep Learning plus compliqué (DDQ avec image input via atari)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport numpy as np\\nimport os\\nimport random\\nimport shutil\\nfrom statistics import mean\\nfrom game_models.base_game_model import BaseGameModel\\nfrom convolutional_neural_network import ConvolutionalNeuralNetwork\\n\\nGAMMA = 0.99\\nMEMORY_SIZE = 900000\\nBATCH_SIZE = 32\\nTRAINING_FREQUENCY = 4\\nTARGET_NETWORK_UPDATE_FREQUENCY = 40000\\nMODEL_PERSISTENCE_UPDATE_FREQUENCY = 10000\\nREPLAY_START_SIZE = 50000\\n\\nEXPLORATION_MAX = 1.0\\nEXPLORATION_MIN = 0.1\\nEXPLORATION_TEST = 0.02\\nEXPLORATION_STEPS = 850000\\nEXPLORATION_DECAY = (EXPLORATION_MAX-EXPLORATION_MIN)/EXPLORATION_STEPS\\n\\n\\nclass DDQNGameModel():\\n\\n    def __init__(self, game_name, mode_name, input_shape, action_space, logger_path, model_path):\\n        self.action_space = action_space\\n        self.input_shape = input_shape\\n        self.model_path = model_path\\n        self.ddqn = ConvolutionalNeuralNetwork(self.input_shape, action_space).model\\n        if os.path.isfile(self.model_path):\\n            self.ddqn.load_weights(self.model_path)\\n\\n    def _save_model(self):\\n        self.ddqn.save_weights(self.model_path)\\n\\n\\nclass DDQNSolver(DDQNGameModel):\\n\\n    def __init__(self, game_name, input_shape, action_space):\\n        testing_model_path = \"./output/neural_nets/\" + game_name + \"/ddqn/testing/model.h5\"\\n        assert os.path.exists(os.path.dirname(testing_model_path)), \"No testing model in: \" + str(testing_model_path)\\n        DDQNGameModel.__init__(self,\\n                               game_name,\\n                               \"DDQN testing\",\\n                               input_shape,\\n                               action_space,\\n                               \"./output/logs/\" + game_name + \"/ddqn/testing/\" + self._get_date() + \"/\",\\n                               testing_model_path)\\n\\n    def move(self, state):\\n        if np.random.rand() < EXPLORATION_TEST:\\n            return random.randrange(self.action_space)\\n        q_values = self.ddqn.predict(np.expand_dims(np.asarray(state).astype(np.float64), axis=0), batch_size=1)\\n        return np.argmax(q_values[0])\\n\\n\\nclass DDQNTrainer(DDQNGameModel):\\n\\n    def __init__(self, game_name, input_shape, action_space):\\n        DDQNGameModel.__init__(self,\\n                               game_name,\\n                               \"DDQN training\",\\n                               input_shape,\\n                               action_space,\\n                               \"./output/logs/\" + game_name + \"/ddqn/training/\" + self._get_date() + \"/\",\\n                               \"./output/neural_nets/\" + game_name + \"/ddqn/\" + self._get_date() + \"/model.h5\")\\n\\n        if os.path.exists(os.path.dirname(self.model_path)):\\n            shutil.rmtree(os.path.dirname(self.model_path), ignore_errors=True)\\n        os.makedirs(os.path.dirname(self.model_path))\\n\\n        self.ddqn_target = ConvolutionalNeuralNetwork(self.input_shape, action_space).model\\n        self._reset_target_network()\\n        self.epsilon = EXPLORATION_MAX\\n        self.memory = []\\n\\n    def move(self, state):\\n        if np.random.rand() < self.epsilon or len(self.memory) < REPLAY_START_SIZE:\\n            return random.randrange(self.action_space)\\n        q_values = self.ddqn.predict(np.expand_dims(np.asarray(state).astype(np.float64), axis=0), batch_size=1)\\n        return np.argmax(q_values[0])\\n\\n    def remember(self, current_state, action, reward, next_state, terminal):\\n        self.memory.append({\"current_state\": current_state,\\n                            \"action\": action,\\n                            \"reward\": reward,\\n                            \"next_state\": next_state,\\n                            \"terminal\": terminal})\\n        if len(self.memory) > MEMORY_SIZE:\\n            self.memory.pop(0)\\n\\n    def step_update(self, total_step):\\n        if len(self.memory) < REPLAY_START_SIZE:\\n            return\\n\\n        if total_step % TRAINING_FREQUENCY == 0:\\n            loss, accuracy, average_max_q = self._train()\\n            self.logger.add_loss(loss)\\n            self.logger.add_accuracy(accuracy)\\n            self.logger.add_q(average_max_q)\\n\\n        self._update_epsilon()\\n\\n        if total_step % MODEL_PERSISTENCE_UPDATE_FREQUENCY == 0:\\n            self._save_model()\\n\\n        if total_step % TARGET_NETWORK_UPDATE_FREQUENCY == 0:\\n            self._reset_target_network()\\n            print(\\'{{\"metric\": \"epsilon\", \"value\": {}}}\\'.format(self.epsilon))\\n            print(\\'{{\"metric\": \"total_step\", \"value\": {}}}\\'.format(total_step))\\n\\n    def _train(self):\\n        batch = np.asarray(random.sample(self.memory, BATCH_SIZE))\\n        if len(batch) < BATCH_SIZE:\\n            return\\n\\n        current_states = []\\n        q_values = []\\n        max_q_values = []\\n\\n        for entry in batch:\\n            current_state = np.expand_dims(np.asarray(entry[\"current_state\"]).astype(np.float64), axis=0)\\n            current_states.append(current_state)\\n            next_state = np.expand_dims(np.asarray(entry[\"next_state\"]).astype(np.float64), axis=0)\\n            next_state_prediction = self.ddqn_target.predict(next_state).ravel()\\n            next_q_value = np.max(next_state_prediction)\\n            q = list(self.ddqn.predict(current_state)[0])\\n            if entry[\"terminal\"]:\\n                q[entry[\"action\"]] = entry[\"reward\"]\\n            else:\\n                q[entry[\"action\"]] = entry[\"reward\"] + GAMMA * next_q_value\\n            q_values.append(q)\\n            max_q_values.append(np.max(q))\\n\\n        fit = self.ddqn.fit(np.asarray(current_states).squeeze(),\\n                            np.asarray(q_values).squeeze(),\\n                            batch_size=BATCH_SIZE,\\n                            verbose=0)\\n        loss = fit.history[\"loss\"][0]\\n        accuracy = fit.history[\"acc\"][0]\\n        return loss, accuracy, mean(max_q_values)\\n\\n    def _update_epsilon(self):\\n        self.epsilon -= EXPLORATION_DECAY\\n        self.epsilon = max(EXPLORATION_MIN, self.epsilon)\\n\\n    def _reset_target_network(self):\\n        self.ddqn_target.set_weights(self.ddqn.get_weights())\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from statistics import mean\n",
    "from game_models.base_game_model import BaseGameModel\n",
    "from convolutional_neural_network import ConvolutionalNeuralNetwork\n",
    "\n",
    "GAMMA = 0.99\n",
    "MEMORY_SIZE = 900000\n",
    "BATCH_SIZE = 32\n",
    "TRAINING_FREQUENCY = 4\n",
    "TARGET_NETWORK_UPDATE_FREQUENCY = 40000\n",
    "MODEL_PERSISTENCE_UPDATE_FREQUENCY = 10000\n",
    "REPLAY_START_SIZE = 50000\n",
    "\n",
    "EXPLORATION_MAX = 1.0\n",
    "EXPLORATION_MIN = 0.1\n",
    "EXPLORATION_TEST = 0.02\n",
    "EXPLORATION_STEPS = 850000\n",
    "EXPLORATION_DECAY = (EXPLORATION_MAX-EXPLORATION_MIN)/EXPLORATION_STEPS\n",
    "\n",
    "\n",
    "class DDQNGameModel():\n",
    "\n",
    "    def __init__(self, game_name, mode_name, input_shape, action_space, logger_path, model_path):\n",
    "        self.action_space = action_space\n",
    "        self.input_shape = input_shape\n",
    "        self.model_path = model_path\n",
    "        self.ddqn = ConvolutionalNeuralNetwork(self.input_shape, action_space).model\n",
    "        if os.path.isfile(self.model_path):\n",
    "            self.ddqn.load_weights(self.model_path)\n",
    "\n",
    "    def _save_model(self):\n",
    "        self.ddqn.save_weights(self.model_path)\n",
    "\n",
    "\n",
    "class DDQNSolver(DDQNGameModel):\n",
    "\n",
    "    def __init__(self, game_name, input_shape, action_space):\n",
    "        testing_model_path = \"./output/neural_nets/\" + game_name + \"/ddqn/testing/model.h5\"\n",
    "        assert os.path.exists(os.path.dirname(testing_model_path)), \"No testing model in: \" + str(testing_model_path)\n",
    "        DDQNGameModel.__init__(self,\n",
    "                               game_name,\n",
    "                               \"DDQN testing\",\n",
    "                               input_shape,\n",
    "                               action_space,\n",
    "                               \"./output/logs/\" + game_name + \"/ddqn/testing/\" + self._get_date() + \"/\",\n",
    "                               testing_model_path)\n",
    "\n",
    "    def move(self, state):\n",
    "        if np.random.rand() < EXPLORATION_TEST:\n",
    "            return random.randrange(self.action_space)\n",
    "        q_values = self.ddqn.predict(np.expand_dims(np.asarray(state).astype(np.float64), axis=0), batch_size=1)\n",
    "        return np.argmax(q_values[0])\n",
    "\n",
    "\n",
    "class DDQNTrainer(DDQNGameModel):\n",
    "\n",
    "    def __init__(self, game_name, input_shape, action_space):\n",
    "        DDQNGameModel.__init__(self,\n",
    "                               game_name,\n",
    "                               \"DDQN training\",\n",
    "                               input_shape,\n",
    "                               action_space,\n",
    "                               \"./output/logs/\" + game_name + \"/ddqn/training/\" + self._get_date() + \"/\",\n",
    "                               \"./output/neural_nets/\" + game_name + \"/ddqn/\" + self._get_date() + \"/model.h5\")\n",
    "\n",
    "        if os.path.exists(os.path.dirname(self.model_path)):\n",
    "            shutil.rmtree(os.path.dirname(self.model_path), ignore_errors=True)\n",
    "        os.makedirs(os.path.dirname(self.model_path))\n",
    "\n",
    "        self.ddqn_target = ConvolutionalNeuralNetwork(self.input_shape, action_space).model\n",
    "        self._reset_target_network()\n",
    "        self.epsilon = EXPLORATION_MAX\n",
    "        self.memory = []\n",
    "\n",
    "    def move(self, state):\n",
    "        if np.random.rand() < self.epsilon or len(self.memory) < REPLAY_START_SIZE:\n",
    "            return random.randrange(self.action_space)\n",
    "        q_values = self.ddqn.predict(np.expand_dims(np.asarray(state).astype(np.float64), axis=0), batch_size=1)\n",
    "        return np.argmax(q_values[0])\n",
    "\n",
    "    def remember(self, current_state, action, reward, next_state, terminal):\n",
    "        self.memory.append({\"current_state\": current_state,\n",
    "                            \"action\": action,\n",
    "                            \"reward\": reward,\n",
    "                            \"next_state\": next_state,\n",
    "                            \"terminal\": terminal})\n",
    "        if len(self.memory) > MEMORY_SIZE:\n",
    "            self.memory.pop(0)\n",
    "\n",
    "    def step_update(self, total_step):\n",
    "        if len(self.memory) < REPLAY_START_SIZE:\n",
    "            return\n",
    "\n",
    "        if total_step % TRAINING_FREQUENCY == 0:\n",
    "            loss, accuracy, average_max_q = self._train()\n",
    "            self.logger.add_loss(loss)\n",
    "            self.logger.add_accuracy(accuracy)\n",
    "            self.logger.add_q(average_max_q)\n",
    "\n",
    "        self._update_epsilon()\n",
    "\n",
    "        if total_step % MODEL_PERSISTENCE_UPDATE_FREQUENCY == 0:\n",
    "            self._save_model()\n",
    "\n",
    "        if total_step % TARGET_NETWORK_UPDATE_FREQUENCY == 0:\n",
    "            self._reset_target_network()\n",
    "            print('{{\"metric\": \"epsilon\", \"value\": {}}}'.format(self.epsilon))\n",
    "            print('{{\"metric\": \"total_step\", \"value\": {}}}'.format(total_step))\n",
    "\n",
    "    def _train(self):\n",
    "        batch = np.asarray(random.sample(self.memory, BATCH_SIZE))\n",
    "        if len(batch) < BATCH_SIZE:\n",
    "            return\n",
    "\n",
    "        current_states = []\n",
    "        q_values = []\n",
    "        max_q_values = []\n",
    "\n",
    "        for entry in batch:\n",
    "            current_state = np.expand_dims(np.asarray(entry[\"current_state\"]).astype(np.float64), axis=0)\n",
    "            current_states.append(current_state)\n",
    "            next_state = np.expand_dims(np.asarray(entry[\"next_state\"]).astype(np.float64), axis=0)\n",
    "            next_state_prediction = self.ddqn_target.predict(next_state).ravel()\n",
    "            next_q_value = np.max(next_state_prediction)\n",
    "            q = list(self.ddqn.predict(current_state)[0])\n",
    "            if entry[\"terminal\"]:\n",
    "                q[entry[\"action\"]] = entry[\"reward\"]\n",
    "            else:\n",
    "                q[entry[\"action\"]] = entry[\"reward\"] + GAMMA * next_q_value\n",
    "            q_values.append(q)\n",
    "            max_q_values.append(np.max(q))\n",
    "\n",
    "        fit = self.ddqn.fit(np.asarray(current_states).squeeze(),\n",
    "                            np.asarray(q_values).squeeze(),\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            verbose=0)\n",
    "        loss = fit.history[\"loss\"][0]\n",
    "        accuracy = fit.history[\"acc\"][0]\n",
    "        return loss, accuracy, mean(max_q_values)\n",
    "\n",
    "    def _update_epsilon(self):\n",
    "        self.epsilon -= EXPLORATION_DECAY\n",
    "        self.epsilon = max(EXPLORATION_MIN, self.epsilon)\n",
    "\n",
    "    def _reset_target_network(self):\n",
    "        self.ddqn_target.set_weights(self.ddqn.get_weights())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from statistics import mean\n",
    "from datetime import datetime\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, Dense\n",
    "\n",
    "GAMMA = 0.99\n",
    "MEMORY_SIZE = 900000\n",
    "BATCH_SIZE = 32\n",
    "TRAINING_FREQUENCY = 4\n",
    "TARGET_NETWORK_UPDATE_FREQUENCY = 40000\n",
    "MODEL_PERSISTENCE_UPDATE_FREQUENCY = 10000\n",
    "REPLAY_START_SIZE = 50000\n",
    "\n",
    "EXPLORATION_MAX = 1.0\n",
    "EXPLORATION_MIN = 0.1\n",
    "EXPLORATION_TEST = 0.02\n",
    "EXPLORATION_STEPS = 850000\n",
    "EXPLORATION_DECAY = (EXPLORATION_MAX-EXPLORATION_MIN)/EXPLORATION_STEPS\n",
    "\n",
    "\n",
    "class DDQNGameModel():\n",
    "\n",
    "    def __init__(self, game_name, mode_name, input_shape, action_space, logger_path, model_path):\n",
    "        self.action_space = action_space\n",
    "        self.input_shape = input_shape\n",
    "        self.model_path = model_path\n",
    "        \n",
    "        #Section Modele neural network\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Conv2D(32,\n",
    "                              8,\n",
    "                              strides=(4, 4),\n",
    "                              padding=\"valid\",\n",
    "                              activation=\"relu\",\n",
    "                              input_shape=input_shape,\n",
    "                              data_format=\"channels_last\"))\n",
    "        self.model.add(Conv2D(64,\n",
    "                              4,\n",
    "                              strides=(2, 2),\n",
    "                              padding=\"valid\",\n",
    "                              activation=\"relu\",\n",
    "                              input_shape=input_shape,\n",
    "                              data_format=\"channels_last\"))\n",
    "        self.model.add(Conv2D(64,\n",
    "                              3,\n",
    "                              strides=(1, 1),\n",
    "                              padding=\"valid\",\n",
    "                              activation=\"relu\",\n",
    "                              input_shape=input_shape,\n",
    "                              data_format=\"channels_last\"))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(512, activation=\"relu\"))\n",
    "        self.model.add(Dense(action_space))\n",
    "        self.model.compile(loss=\"mean_squared_error\",\n",
    "                           optimizer=RMSprop(lr=0.00025,\n",
    "                                             rho=0.95,\n",
    "                                             epsilon=0.01),\n",
    "                           metrics=[\"accuracy\"])\n",
    "        #self.model.summary()\n",
    "        \n",
    "        self.ddqn = self.model\n",
    "        \n",
    "        \n",
    "        \n",
    "        if os.path.isfile(self.model_path):\n",
    "            self.ddqn.load_weights(self.model_path)\n",
    "\n",
    "    def _save_model(self):\n",
    "        self.ddqn.save_weights(self.model_path)\n",
    "\n",
    "\n",
    "class DDQNSolver(DDQNGameModel):\n",
    "\n",
    "    def __init__(self, game_name, input_shape, action_space):\n",
    "        testing_model_path = \"./output/neural_nets/\" + game_name + \"/ddqn/testing/model.h5\"\n",
    "        assert os.path.exists(os.path.dirname(testing_model_path)), \"No testing model in: \" + str(testing_model_path)\n",
    "        DDQNGameModel.__init__(self,\n",
    "                               game_name,\n",
    "                               \"DDQN testing\",\n",
    "                               input_shape,\n",
    "                               action_space,\n",
    "                               \"./output/logs/\" + game_name + \"/ddqn/testing/\" + str(datetime.now().strftime(\"%d-%m-%y_$h-$m\")) + \"/\",\n",
    "                               testing_model_path)\n",
    "\n",
    "    def move(self, state):\n",
    "        if np.random.rand() < EXPLORATION_TEST:\n",
    "            return random.randrange(self.action_space)\n",
    "        q_values = self.ddqn.predict(np.expand_dims(np.asarray(state).astype(np.float64), axis=0), batch_size=1)\n",
    "        return np.argmax(q_values[0])\n",
    "\n",
    "\n",
    "class DDQNTrainer(DDQNGameModel):\n",
    "\n",
    "    def __init__(self, game_name, input_shape, action_space):\n",
    "        DDQNGameModel.__init__(self,\n",
    "                               game_name,\n",
    "                               \"DDQN training\",\n",
    "                               input_shape,\n",
    "                               action_space,\n",
    "                               \"./output/logs/\" + game_name + \"/ddqn/training/\" + str(datetime.now().strftime(\"%d-%m-%y_$h-$m\")) + \"/\",\n",
    "                               \"./output/neural_nets/\" + game_name + \"/ddqn/\" + str(datetime.now().strftime(\"%d-%m-%y_$h-$m\")) + \"/model.h5\")\n",
    "\n",
    "        if os.path.exists(os.path.dirname(self.model_path)):\n",
    "            shutil.rmtree(os.path.dirname(self.model_path), ignore_errors=True)\n",
    "        os.makedirs(os.path.dirname(self.model_path))\n",
    "\n",
    "        #Section Modele neural network\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Conv2D(32,\n",
    "                              8,\n",
    "                              strides=(4, 4),\n",
    "                              padding=\"valid\",\n",
    "                              activation=\"relu\",\n",
    "                              input_shape=input_shape,\n",
    "                              data_format=\"channels_last\"))\n",
    "        self.model.add(Conv2D(64,\n",
    "                              4,\n",
    "                              strides=(2, 2),\n",
    "                              padding=\"valid\",\n",
    "                              activation=\"relu\",\n",
    "                              input_shape=input_shape,\n",
    "                              data_format=\"channels_last\"))\n",
    "        self.model.add(Conv2D(64,\n",
    "                              3,\n",
    "                              strides=(1, 1),\n",
    "                              padding=\"valid\",\n",
    "                              activation=\"relu\",\n",
    "                              input_shape=input_shape,\n",
    "                              data_format=\"channels_last\"))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(512, activation=\"relu\"))\n",
    "        self.model.add(Dense(action_space))\n",
    "        self.model.compile(loss=\"mean_squared_error\",\n",
    "                           optimizer=RMSprop(lr=0.00025,\n",
    "                                             rho=0.95,\n",
    "                                             epsilon=0.01),\n",
    "                           metrics=[\"accuracy\"])\n",
    "        #self.model.summary()\n",
    "        \n",
    "        self.ddqn_target = self.model\n",
    "        self._reset_target_network()\n",
    "        self.epsilon = EXPLORATION_MAX\n",
    "        self.memory = []\n",
    "\n",
    "    def move(self, state):\n",
    "        if np.random.rand() < self.epsilon or len(self.memory) < REPLAY_START_SIZE:\n",
    "            return random.randrange(self.action_space)\n",
    "        q_values = self.ddqn.predict(np.expand_dims(np.asarray(state).astype(np.float64), axis=0), batch_size=1)\n",
    "        return np.argmax(q_values[0])\n",
    "\n",
    "    def remember(self, current_state, action, reward, next_state, terminal):\n",
    "        self.memory.append({\"current_state\": current_state,\n",
    "                            \"action\": action,\n",
    "                            \"reward\": reward,\n",
    "                            \"next_state\": next_state,\n",
    "                            \"terminal\": terminal})\n",
    "        if len(self.memory) > MEMORY_SIZE:\n",
    "            self.memory.pop(0)\n",
    "\n",
    "    def step_update(self, total_step):\n",
    "        if len(self.memory) < REPLAY_START_SIZE:\n",
    "            return\n",
    "\n",
    "        if total_step % TRAINING_FREQUENCY == 0:\n",
    "            loss, accuracy, average_max_q = self._train()\n",
    "            self.logger.add_loss(loss)\n",
    "            self.logger.add_accuracy(accuracy)\n",
    "            self.logger.add_q(average_max_q)\n",
    "\n",
    "        self._update_epsilon()\n",
    "\n",
    "        if total_step % MODEL_PERSISTENCE_UPDATE_FREQUENCY == 0:\n",
    "            self._save_model()\n",
    "\n",
    "        if total_step % TARGET_NETWORK_UPDATE_FREQUENCY == 0:\n",
    "            self._reset_target_network()\n",
    "            print('{{\"metric\": \"epsilon\", \"value\": {}}}'.format(self.epsilon))\n",
    "            print('{{\"metric\": \"total_step\", \"value\": {}}}'.format(total_step))\n",
    "\n",
    "    def _train(self):\n",
    "        batch = np.asarray(random.sample(self.memory, BATCH_SIZE))\n",
    "        if len(batch) < BATCH_SIZE:\n",
    "            return\n",
    "\n",
    "        current_states = []\n",
    "        q_values = []\n",
    "        max_q_values = []\n",
    "\n",
    "        for entry in batch:\n",
    "            current_state = np.expand_dims(np.asarray(entry[\"current_state\"]).astype(np.float64), axis=0)\n",
    "            current_states.append(current_state)\n",
    "            next_state = np.expand_dims(np.asarray(entry[\"next_state\"]).astype(np.float64), axis=0)\n",
    "            next_state_prediction = self.ddqn_target.predict(next_state).ravel()\n",
    "            next_q_value = np.max(next_state_prediction)\n",
    "            q = list(self.ddqn.predict(current_state)[0])\n",
    "            if entry[\"terminal\"]:\n",
    "                q[entry[\"action\"]] = entry[\"reward\"]\n",
    "            else:\n",
    "                q[entry[\"action\"]] = entry[\"reward\"] + GAMMA * next_q_value\n",
    "            q_values.append(q)\n",
    "            max_q_values.append(np.max(q))\n",
    "\n",
    "        fit = self.ddqn.fit(np.asarray(current_states).squeeze(),\n",
    "                            np.asarray(q_values).squeeze(),\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            verbose=0)\n",
    "        loss = fit.history[\"loss\"][0]\n",
    "        accuracy = fit.history[\"acc\"][0]\n",
    "        return loss, accuracy, mean(max_q_values)\n",
    "\n",
    "    def _update_epsilon(self):\n",
    "        self.epsilon -= EXPLORATION_DECAY\n",
    "        self.epsilon = max(EXPLORATION_MIN, self.epsilon)\n",
    "\n",
    "    def _reset_target_network(self):\n",
    "        self.ddqn_target.set_weights(self.ddqn.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def cartpole(EPISODES):\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    observation_space = env.observation_space.shape[0]\n",
    "    action_space = env.action_space.n\n",
    "    dqn_solver = DQNSolver(observation_space, action_space)\n",
    "\n",
    "    \n",
    "    final = []\n",
    "    for e in range(EPISODES):\n",
    "        \n",
    "        state = env.reset()\n",
    "        state = np.reshape(state, [1, observation_space])\n",
    "        step = 0\n",
    "        while True:\n",
    "            step += 1\n",
    "            #env.render()\n",
    "            action = dqn_solver.act(state)\n",
    "            state_next, reward, terminal, info = env.step(action)\n",
    "            reward = reward if not terminal else -reward\n",
    "            state_next = np.reshape(state_next, [1, observation_space])\n",
    "            dqn_solver.remember(state, action, reward, state_next, terminal)\n",
    "            state = state_next\n",
    "            if terminal:\n",
    "                print(\"Run: \" + str(e) + \", exploration: \" + str(dqn_solver.exploration_rate) + \", score: \" + str(step))\n",
    "                break\n",
    "            dqn_solver.experience_replay()\n",
    "        final.append(step)\n",
    "            \n",
    "    dqn_solver.save(\"./cartpole-dqn.h5\")\n",
    "    #print(dqn_solver.model.layers[0].get_weights()[0])\n",
    "    return final\n",
    "\"\"\"\n",
    "import imageio\n",
    "\n",
    "\n",
    "def cartpole2(EPISODES,STEP_MAX,render):\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    action_space = env.action_space.n\n",
    "    im = imageio.imread('fake.png')\n",
    "    im=np.dot(im[...,:3], [0.299, 0.587, 0.114])\n",
    "    print(im.shape)\n",
    "\n",
    "    game_model = DDQNTrainer('fake_game_name', (224, 256,1), action_space)\n",
    "    \n",
    "    final = []\n",
    "    run = 0\n",
    "    total_step = 0\n",
    "    while True:\n",
    "        if run >= EPISODES:\n",
    "            print(\"Finis les episodes\")\n",
    "            break\n",
    "\n",
    "        run += 1\n",
    "        current_state = env.reset()\n",
    "        step = 0\n",
    "        score = 0\n",
    "        while True:\n",
    "            if total_step >= STEP_MAX:\n",
    "                print(\"Step maximum en tout atteint\")\n",
    "                return final #Je veux break de toutes les loops\n",
    "            total_step += 1\n",
    "            step += 1\n",
    "\n",
    "            if render:\n",
    "                env.render()\n",
    "\n",
    "            action = game_model.move(current_state)\n",
    "            next_state, reward, terminal, info = env.step(action)\n",
    "            \n",
    "            \n",
    "            \n",
    "            next_state = im #add\n",
    "            \n",
    "            \n",
    "            \n",
    "            score += reward\n",
    "            game_model.remember(current_state, action, reward, next_state, terminal)\n",
    "            current_state = next_state\n",
    "\n",
    "            game_model.step_update(total_step)\n",
    "\n",
    "            if terminal:\n",
    "                final.append([score, step, run])\n",
    "                break\n",
    "                \n",
    "        print(\"Run: \" + str(run) + \", tot_step: \" + str(total_step) + \", score: \" + str(score))\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 256)\n",
      "Run: 1, tot_step: 15, score: 15.0\n",
      "Run: 2, tot_step: 26, score: 11.0\n",
      "Run: 3, tot_step: 51, score: 25.0\n",
      "Run: 4, tot_step: 100, score: 49.0\n",
      "Run: 5, tot_step: 124, score: 24.0\n",
      "Run: 6, tot_step: 196, score: 72.0\n",
      "Run: 7, tot_step: 257, score: 61.0\n",
      "Run: 8, tot_step: 278, score: 21.0\n",
      "Run: 9, tot_step: 292, score: 14.0\n",
      "Run: 10, tot_step: 307, score: 15.0\n",
      "Run: 11, tot_step: 334, score: 27.0\n",
      "Run: 12, tot_step: 351, score: 17.0\n",
      "Run: 13, tot_step: 365, score: 14.0\n",
      "Run: 14, tot_step: 409, score: 44.0\n",
      "Run: 15, tot_step: 430, score: 21.0\n",
      "Run: 16, tot_step: 450, score: 20.0\n",
      "Run: 17, tot_step: 486, score: 36.0\n",
      "Run: 18, tot_step: 542, score: 56.0\n",
      "Run: 19, tot_step: 567, score: 25.0\n",
      "Run: 20, tot_step: 591, score: 24.0\n",
      "Run: 21, tot_step: 620, score: 29.0\n",
      "Run: 22, tot_step: 654, score: 34.0\n",
      "Run: 23, tot_step: 668, score: 14.0\n",
      "Run: 24, tot_step: 687, score: 19.0\n",
      "Run: 25, tot_step: 711, score: 24.0\n",
      "Run: 26, tot_step: 727, score: 16.0\n",
      "Run: 27, tot_step: 747, score: 20.0\n",
      "Run: 28, tot_step: 760, score: 13.0\n",
      "Run: 29, tot_step: 802, score: 42.0\n",
      "Run: 30, tot_step: 833, score: 31.0\n",
      "Run: 31, tot_step: 854, score: 21.0\n",
      "Run: 32, tot_step: 875, score: 21.0\n",
      "Run: 33, tot_step: 886, score: 11.0\n",
      "Run: 34, tot_step: 897, score: 11.0\n",
      "Run: 35, tot_step: 914, score: 17.0\n",
      "Run: 36, tot_step: 932, score: 18.0\n",
      "Run: 37, tot_step: 977, score: 45.0\n",
      "Run: 38, tot_step: 988, score: 11.0\n",
      "Run: 39, tot_step: 1000, score: 12.0\n",
      "Run: 40, tot_step: 1021, score: 21.0\n",
      "Run: 41, tot_step: 1037, score: 16.0\n",
      "Run: 42, tot_step: 1066, score: 29.0\n",
      "Run: 43, tot_step: 1085, score: 19.0\n",
      "Run: 44, tot_step: 1096, score: 11.0\n",
      "Run: 45, tot_step: 1113, score: 17.0\n",
      "Run: 46, tot_step: 1127, score: 14.0\n",
      "Run: 47, tot_step: 1142, score: 15.0\n",
      "Run: 48, tot_step: 1155, score: 13.0\n",
      "Run: 49, tot_step: 1176, score: 21.0\n",
      "Run: 50, tot_step: 1207, score: 31.0\n",
      "Run: 51, tot_step: 1223, score: 16.0\n",
      "Run: 52, tot_step: 1233, score: 10.0\n",
      "Run: 53, tot_step: 1244, score: 11.0\n",
      "Run: 54, tot_step: 1253, score: 9.0\n",
      "Run: 55, tot_step: 1271, score: 18.0\n",
      "Run: 56, tot_step: 1317, score: 46.0\n",
      "Run: 57, tot_step: 1357, score: 40.0\n",
      "Run: 58, tot_step: 1378, score: 21.0\n",
      "Run: 59, tot_step: 1402, score: 24.0\n",
      "Run: 60, tot_step: 1419, score: 17.0\n",
      "Run: 61, tot_step: 1444, score: 25.0\n",
      "Run: 62, tot_step: 1463, score: 19.0\n",
      "Run: 63, tot_step: 1493, score: 30.0\n",
      "Run: 64, tot_step: 1510, score: 17.0\n",
      "Run: 65, tot_step: 1519, score: 9.0\n",
      "Run: 66, tot_step: 1536, score: 17.0\n",
      "Run: 67, tot_step: 1561, score: 25.0\n",
      "Run: 68, tot_step: 1579, score: 18.0\n",
      "Run: 69, tot_step: 1616, score: 37.0\n",
      "Run: 70, tot_step: 1647, score: 31.0\n",
      "Run: 71, tot_step: 1680, score: 33.0\n",
      "Run: 72, tot_step: 1723, score: 43.0\n",
      "Run: 73, tot_step: 1735, score: 12.0\n",
      "Run: 74, tot_step: 1751, score: 16.0\n",
      "Run: 75, tot_step: 1761, score: 10.0\n",
      "Run: 76, tot_step: 1787, score: 26.0\n",
      "Run: 77, tot_step: 1800, score: 13.0\n",
      "Run: 78, tot_step: 1819, score: 19.0\n",
      "Run: 79, tot_step: 1880, score: 61.0\n",
      "Run: 80, tot_step: 1901, score: 21.0\n",
      "Run: 81, tot_step: 1914, score: 13.0\n",
      "Run: 82, tot_step: 1984, score: 70.0\n",
      "Run: 83, tot_step: 2000, score: 16.0\n",
      "Run: 84, tot_step: 2019, score: 19.0\n",
      "Run: 85, tot_step: 2051, score: 32.0\n",
      "Run: 86, tot_step: 2104, score: 53.0\n",
      "Run: 87, tot_step: 2116, score: 12.0\n",
      "Run: 88, tot_step: 2140, score: 24.0\n",
      "Run: 89, tot_step: 2162, score: 22.0\n",
      "Run: 90, tot_step: 2172, score: 10.0\n",
      "Run: 91, tot_step: 2185, score: 13.0\n",
      "Run: 92, tot_step: 2201, score: 16.0\n",
      "Run: 93, tot_step: 2224, score: 23.0\n",
      "Run: 94, tot_step: 2255, score: 31.0\n",
      "Run: 95, tot_step: 2274, score: 19.0\n",
      "Run: 96, tot_step: 2300, score: 26.0\n",
      "Run: 97, tot_step: 2329, score: 29.0\n",
      "Run: 98, tot_step: 2346, score: 17.0\n",
      "Run: 99, tot_step: 2356, score: 10.0\n",
      "Run: 100, tot_step: 2370, score: 14.0\n",
      "Run: 101, tot_step: 2387, score: 17.0\n",
      "Run: 102, tot_step: 2404, score: 17.0\n",
      "Run: 103, tot_step: 2435, score: 31.0\n",
      "Run: 104, tot_step: 2447, score: 12.0\n",
      "Run: 105, tot_step: 2500, score: 53.0\n",
      "Run: 106, tot_step: 2524, score: 24.0\n",
      "Run: 107, tot_step: 2550, score: 26.0\n",
      "Run: 108, tot_step: 2573, score: 23.0\n",
      "Run: 109, tot_step: 2601, score: 28.0\n",
      "Run: 110, tot_step: 2643, score: 42.0\n",
      "Run: 111, tot_step: 2669, score: 26.0\n",
      "Run: 112, tot_step: 2683, score: 14.0\n",
      "Run: 113, tot_step: 2721, score: 38.0\n",
      "Run: 114, tot_step: 2746, score: 25.0\n",
      "Run: 115, tot_step: 2771, score: 25.0\n",
      "Run: 116, tot_step: 2791, score: 20.0\n",
      "Run: 117, tot_step: 2811, score: 20.0\n",
      "Run: 118, tot_step: 2841, score: 30.0\n",
      "Run: 119, tot_step: 2899, score: 58.0\n",
      "Run: 120, tot_step: 2913, score: 14.0\n",
      "Run: 121, tot_step: 2944, score: 31.0\n",
      "Run: 122, tot_step: 3000, score: 56.0\n",
      "Run: 123, tot_step: 3032, score: 32.0\n",
      "Run: 124, tot_step: 3047, score: 15.0\n",
      "Run: 125, tot_step: 3107, score: 60.0\n",
      "Run: 126, tot_step: 3133, score: 26.0\n",
      "Run: 127, tot_step: 3150, score: 17.0\n",
      "Run: 128, tot_step: 3177, score: 27.0\n",
      "Run: 129, tot_step: 3193, score: 16.0\n",
      "Run: 130, tot_step: 3227, score: 34.0\n",
      "Run: 131, tot_step: 3249, score: 22.0\n",
      "Run: 132, tot_step: 3287, score: 38.0\n",
      "Run: 133, tot_step: 3300, score: 13.0\n",
      "Run: 134, tot_step: 3321, score: 21.0\n",
      "Run: 135, tot_step: 3342, score: 21.0\n",
      "Run: 136, tot_step: 3360, score: 18.0\n",
      "Run: 137, tot_step: 3378, score: 18.0\n",
      "Run: 138, tot_step: 3395, score: 17.0\n",
      "Run: 139, tot_step: 3412, score: 17.0\n",
      "Run: 140, tot_step: 3438, score: 26.0\n",
      "Run: 141, tot_step: 3457, score: 19.0\n",
      "Run: 142, tot_step: 3482, score: 25.0\n",
      "Run: 143, tot_step: 3492, score: 10.0\n",
      "Run: 144, tot_step: 3509, score: 17.0\n",
      "Run: 145, tot_step: 3535, score: 26.0\n",
      "Run: 146, tot_step: 3550, score: 15.0\n",
      "Run: 147, tot_step: 3566, score: 16.0\n",
      "Run: 148, tot_step: 3599, score: 33.0\n",
      "Run: 149, tot_step: 3647, score: 48.0\n",
      "Run: 150, tot_step: 3677, score: 30.0\n",
      "Run: 151, tot_step: 3688, score: 11.0\n",
      "Run: 152, tot_step: 3709, score: 21.0\n",
      "Run: 153, tot_step: 3719, score: 10.0\n",
      "Run: 154, tot_step: 3741, score: 22.0\n",
      "Run: 155, tot_step: 3790, score: 49.0\n",
      "Run: 156, tot_step: 3824, score: 34.0\n",
      "Run: 157, tot_step: 3857, score: 33.0\n",
      "Run: 158, tot_step: 3879, score: 22.0\n",
      "Run: 159, tot_step: 3891, score: 12.0\n",
      "Run: 160, tot_step: 3911, score: 20.0\n",
      "Run: 161, tot_step: 3928, score: 17.0\n",
      "Run: 162, tot_step: 3943, score: 15.0\n",
      "Run: 163, tot_step: 3993, score: 50.0\n",
      "Run: 164, tot_step: 4028, score: 35.0\n",
      "Run: 165, tot_step: 4054, score: 26.0\n",
      "Run: 166, tot_step: 4108, score: 54.0\n",
      "Run: 167, tot_step: 4121, score: 13.0\n",
      "Run: 168, tot_step: 4142, score: 21.0\n",
      "Run: 169, tot_step: 4176, score: 34.0\n",
      "Run: 170, tot_step: 4217, score: 41.0\n",
      "Run: 171, tot_step: 4269, score: 52.0\n",
      "Run: 172, tot_step: 4289, score: 20.0\n",
      "Run: 173, tot_step: 4304, score: 15.0\n",
      "Run: 174, tot_step: 4318, score: 14.0\n",
      "Run: 175, tot_step: 4332, score: 14.0\n",
      "Run: 176, tot_step: 4376, score: 44.0\n",
      "Run: 177, tot_step: 4393, score: 17.0\n",
      "Run: 178, tot_step: 4417, score: 24.0\n",
      "Run: 179, tot_step: 4432, score: 15.0\n",
      "Run: 180, tot_step: 4446, score: 14.0\n",
      "Run: 181, tot_step: 4507, score: 61.0\n",
      "Run: 182, tot_step: 4521, score: 14.0\n",
      "Run: 183, tot_step: 4560, score: 39.0\n",
      "Run: 184, tot_step: 4594, score: 34.0\n",
      "Run: 185, tot_step: 4604, score: 10.0\n",
      "Run: 186, tot_step: 4619, score: 15.0\n",
      "Run: 187, tot_step: 4633, score: 14.0\n",
      "Run: 188, tot_step: 4653, score: 20.0\n",
      "Run: 189, tot_step: 4708, score: 55.0\n",
      "Run: 190, tot_step: 4762, score: 54.0\n",
      "Run: 191, tot_step: 4787, score: 25.0\n",
      "Run: 192, tot_step: 4795, score: 8.0\n",
      "Run: 193, tot_step: 4806, score: 11.0\n",
      "Run: 194, tot_step: 4817, score: 11.0\n",
      "Run: 195, tot_step: 4836, score: 19.0\n",
      "Run: 196, tot_step: 4882, score: 46.0\n",
      "Run: 197, tot_step: 4900, score: 18.0\n",
      "Run: 198, tot_step: 4918, score: 18.0\n",
      "Run: 199, tot_step: 4933, score: 15.0\n",
      "Run: 200, tot_step: 4943, score: 10.0\n",
      "Run: 201, tot_step: 4959, score: 16.0\n",
      "Run: 202, tot_step: 4981, score: 22.0\n",
      "Run: 203, tot_step: 4994, score: 13.0\n",
      "Run: 204, tot_step: 5007, score: 13.0\n",
      "Run: 205, tot_step: 5023, score: 16.0\n",
      "Run: 206, tot_step: 5041, score: 18.0\n",
      "Run: 207, tot_step: 5059, score: 18.0\n",
      "Run: 208, tot_step: 5092, score: 33.0\n",
      "Run: 209, tot_step: 5108, score: 16.0\n",
      "Run: 210, tot_step: 5123, score: 15.0\n",
      "Run: 211, tot_step: 5137, score: 14.0\n",
      "Run: 212, tot_step: 5157, score: 20.0\n",
      "Run: 213, tot_step: 5183, score: 26.0\n",
      "Run: 214, tot_step: 5202, score: 19.0\n",
      "Run: 215, tot_step: 5217, score: 15.0\n",
      "Run: 216, tot_step: 5245, score: 28.0\n",
      "Run: 217, tot_step: 5258, score: 13.0\n",
      "Run: 218, tot_step: 5277, score: 19.0\n",
      "Run: 219, tot_step: 5290, score: 13.0\n",
      "Run: 220, tot_step: 5304, score: 14.0\n",
      "Run: 221, tot_step: 5340, score: 36.0\n",
      "Run: 222, tot_step: 5375, score: 35.0\n",
      "Run: 223, tot_step: 5391, score: 16.0\n",
      "Run: 224, tot_step: 5411, score: 20.0\n",
      "Run: 225, tot_step: 5451, score: 40.0\n",
      "Run: 226, tot_step: 5463, score: 12.0\n",
      "Run: 227, tot_step: 5483, score: 20.0\n",
      "Run: 228, tot_step: 5552, score: 69.0\n",
      "Run: 229, tot_step: 5575, score: 23.0\n",
      "Run: 230, tot_step: 5601, score: 26.0\n",
      "Run: 231, tot_step: 5612, score: 11.0\n",
      "Run: 232, tot_step: 5646, score: 34.0\n",
      "Run: 233, tot_step: 5663, score: 17.0\n",
      "Run: 234, tot_step: 5693, score: 30.0\n",
      "Run: 235, tot_step: 5735, score: 42.0\n",
      "Run: 236, tot_step: 5748, score: 13.0\n",
      "Run: 237, tot_step: 5765, score: 17.0\n",
      "Run: 238, tot_step: 5814, score: 49.0\n",
      "Run: 239, tot_step: 5837, score: 23.0\n",
      "Run: 240, tot_step: 5863, score: 26.0\n",
      "Run: 241, tot_step: 5878, score: 15.0\n",
      "Run: 242, tot_step: 5914, score: 36.0\n",
      "Run: 243, tot_step: 5929, score: 15.0\n",
      "Run: 244, tot_step: 5941, score: 12.0\n",
      "Run: 245, tot_step: 5971, score: 30.0\n",
      "Run: 246, tot_step: 5990, score: 19.0\n",
      "Run: 247, tot_step: 6008, score: 18.0\n",
      "Run: 248, tot_step: 6023, score: 15.0\n",
      "Run: 249, tot_step: 6047, score: 24.0\n",
      "Run: 250, tot_step: 6066, score: 19.0\n",
      "Run: 251, tot_step: 6093, score: 27.0\n",
      "Run: 252, tot_step: 6125, score: 32.0\n",
      "Run: 253, tot_step: 6156, score: 31.0\n",
      "Run: 254, tot_step: 6201, score: 45.0\n",
      "Run: 255, tot_step: 6215, score: 14.0\n",
      "Run: 256, tot_step: 6228, score: 13.0\n",
      "Run: 257, tot_step: 6243, score: 15.0\n",
      "Run: 258, tot_step: 6254, score: 11.0\n",
      "Run: 259, tot_step: 6293, score: 39.0\n",
      "Run: 260, tot_step: 6305, score: 12.0\n",
      "Run: 261, tot_step: 6316, score: 11.0\n",
      "Run: 262, tot_step: 6332, score: 16.0\n",
      "Run: 263, tot_step: 6349, score: 17.0\n",
      "Run: 264, tot_step: 6384, score: 35.0\n",
      "Run: 265, tot_step: 6398, score: 14.0\n",
      "Run: 266, tot_step: 6411, score: 13.0\n",
      "Run: 267, tot_step: 6429, score: 18.0\n",
      "Run: 268, tot_step: 6443, score: 14.0\n",
      "Run: 269, tot_step: 6461, score: 18.0\n",
      "Run: 270, tot_step: 6475, score: 14.0\n",
      "Run: 271, tot_step: 6492, score: 17.0\n",
      "Run: 272, tot_step: 6538, score: 46.0\n",
      "Run: 273, tot_step: 6550, score: 12.0\n",
      "Run: 274, tot_step: 6567, score: 17.0\n",
      "Run: 275, tot_step: 6582, score: 15.0\n",
      "Run: 276, tot_step: 6597, score: 15.0\n",
      "Run: 277, tot_step: 6607, score: 10.0\n",
      "Run: 278, tot_step: 6620, score: 13.0\n",
      "Run: 279, tot_step: 6633, score: 13.0\n",
      "Run: 280, tot_step: 6645, score: 12.0\n",
      "Run: 281, tot_step: 6670, score: 25.0\n",
      "Run: 282, tot_step: 6686, score: 16.0\n",
      "Run: 283, tot_step: 6696, score: 10.0\n",
      "Run: 284, tot_step: 6714, score: 18.0\n",
      "Run: 285, tot_step: 6725, score: 11.0\n",
      "Run: 286, tot_step: 6745, score: 20.0\n",
      "Run: 287, tot_step: 6755, score: 10.0\n",
      "Run: 288, tot_step: 6785, score: 30.0\n",
      "Run: 289, tot_step: 6797, score: 12.0\n",
      "Run: 290, tot_step: 6811, score: 14.0\n",
      "Run: 291, tot_step: 6836, score: 25.0\n",
      "Run: 292, tot_step: 6881, score: 45.0\n",
      "Run: 293, tot_step: 6900, score: 19.0\n",
      "Run: 294, tot_step: 6913, score: 13.0\n",
      "Run: 295, tot_step: 6931, score: 18.0\n",
      "Run: 296, tot_step: 6950, score: 19.0\n",
      "Run: 297, tot_step: 6982, score: 32.0\n",
      "Run: 298, tot_step: 6998, score: 16.0\n",
      "Run: 299, tot_step: 7017, score: 19.0\n",
      "Run: 300, tot_step: 7032, score: 15.0\n",
      "Run: 301, tot_step: 7057, score: 25.0\n",
      "Run: 302, tot_step: 7102, score: 45.0\n",
      "Run: 303, tot_step: 7117, score: 15.0\n",
      "Run: 304, tot_step: 7162, score: 45.0\n",
      "Run: 305, tot_step: 7178, score: 16.0\n",
      "Run: 306, tot_step: 7196, score: 18.0\n",
      "Run: 307, tot_step: 7210, score: 14.0\n",
      "Run: 308, tot_step: 7238, score: 28.0\n",
      "Run: 309, tot_step: 7251, score: 13.0\n",
      "Run: 310, tot_step: 7264, score: 13.0\n",
      "Run: 311, tot_step: 7279, score: 15.0\n",
      "Run: 312, tot_step: 7291, score: 12.0\n",
      "Run: 313, tot_step: 7312, score: 21.0\n",
      "Run: 314, tot_step: 7326, score: 14.0\n",
      "Run: 315, tot_step: 7348, score: 22.0\n",
      "Run: 316, tot_step: 7387, score: 39.0\n",
      "Run: 317, tot_step: 7399, score: 12.0\n",
      "Run: 318, tot_step: 7411, score: 12.0\n",
      "Run: 319, tot_step: 7422, score: 11.0\n",
      "Run: 320, tot_step: 7439, score: 17.0\n",
      "Run: 321, tot_step: 7458, score: 19.0\n",
      "Run: 322, tot_step: 7482, score: 24.0\n",
      "Run: 323, tot_step: 7496, score: 14.0\n",
      "Run: 324, tot_step: 7527, score: 31.0\n",
      "Run: 325, tot_step: 7550, score: 23.0\n",
      "Run: 326, tot_step: 7569, score: 19.0\n",
      "Run: 327, tot_step: 7595, score: 26.0\n",
      "Run: 328, tot_step: 7619, score: 24.0\n",
      "Run: 329, tot_step: 7654, score: 35.0\n",
      "Run: 330, tot_step: 7685, score: 31.0\n",
      "Run: 331, tot_step: 7723, score: 38.0\n",
      "Run: 332, tot_step: 7797, score: 74.0\n",
      "Run: 333, tot_step: 7837, score: 40.0\n",
      "Run: 334, tot_step: 7847, score: 10.0\n",
      "Run: 335, tot_step: 7870, score: 23.0\n",
      "Run: 336, tot_step: 7883, score: 13.0\n",
      "Run: 337, tot_step: 7914, score: 31.0\n",
      "Run: 338, tot_step: 7937, score: 23.0\n",
      "Run: 339, tot_step: 7955, score: 18.0\n",
      "Run: 340, tot_step: 7978, score: 23.0\n",
      "Run: 341, tot_step: 7994, score: 16.0\n",
      "Run: 342, tot_step: 8006, score: 12.0\n",
      "Run: 343, tot_step: 8041, score: 35.0\n",
      "Run: 344, tot_step: 8054, score: 13.0\n",
      "Run: 345, tot_step: 8067, score: 13.0\n",
      "Run: 346, tot_step: 8110, score: 43.0\n",
      "Run: 347, tot_step: 8128, score: 18.0\n",
      "Run: 348, tot_step: 8162, score: 34.0\n",
      "Run: 349, tot_step: 8193, score: 31.0\n",
      "Run: 350, tot_step: 8206, score: 13.0\n",
      "Run: 351, tot_step: 8230, score: 24.0\n",
      "Run: 352, tot_step: 8239, score: 9.0\n",
      "Run: 353, tot_step: 8257, score: 18.0\n",
      "Run: 354, tot_step: 8270, score: 13.0\n",
      "Run: 355, tot_step: 8294, score: 24.0\n",
      "Run: 356, tot_step: 8308, score: 14.0\n",
      "Run: 357, tot_step: 8326, score: 18.0\n",
      "Run: 358, tot_step: 8368, score: 42.0\n",
      "Run: 359, tot_step: 8392, score: 24.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 360, tot_step: 8430, score: 38.0\n",
      "Run: 361, tot_step: 8446, score: 16.0\n",
      "Run: 362, tot_step: 8461, score: 15.0\n",
      "Run: 363, tot_step: 8473, score: 12.0\n",
      "Run: 364, tot_step: 8515, score: 42.0\n",
      "Run: 365, tot_step: 8528, score: 13.0\n",
      "Run: 366, tot_step: 8545, score: 17.0\n",
      "Run: 367, tot_step: 8603, score: 58.0\n",
      "Run: 368, tot_step: 8621, score: 18.0\n",
      "Run: 369, tot_step: 8658, score: 37.0\n",
      "Run: 370, tot_step: 8690, score: 32.0\n",
      "Run: 371, tot_step: 8721, score: 31.0\n",
      "Run: 372, tot_step: 8740, score: 19.0\n",
      "Run: 373, tot_step: 8753, score: 13.0\n",
      "Run: 374, tot_step: 8766, score: 13.0\n",
      "Run: 375, tot_step: 8778, score: 12.0\n",
      "Run: 376, tot_step: 8805, score: 27.0\n",
      "Run: 377, tot_step: 8825, score: 20.0\n",
      "Run: 378, tot_step: 8836, score: 11.0\n",
      "Run: 379, tot_step: 8855, score: 19.0\n",
      "Run: 380, tot_step: 8885, score: 30.0\n",
      "Run: 381, tot_step: 8906, score: 21.0\n",
      "Run: 382, tot_step: 8934, score: 28.0\n",
      "Run: 383, tot_step: 8947, score: 13.0\n",
      "Run: 384, tot_step: 8959, score: 12.0\n",
      "Run: 385, tot_step: 9015, score: 56.0\n",
      "Run: 386, tot_step: 9029, score: 14.0\n",
      "Run: 387, tot_step: 9045, score: 16.0\n",
      "Run: 388, tot_step: 9065, score: 20.0\n",
      "Run: 389, tot_step: 9079, score: 14.0\n",
      "Run: 390, tot_step: 9129, score: 50.0\n",
      "Run: 391, tot_step: 9141, score: 12.0\n",
      "Run: 392, tot_step: 9168, score: 27.0\n",
      "Run: 393, tot_step: 9178, score: 10.0\n",
      "Run: 394, tot_step: 9195, score: 17.0\n",
      "Run: 395, tot_step: 9211, score: 16.0\n",
      "Run: 396, tot_step: 9232, score: 21.0\n",
      "Run: 397, tot_step: 9249, score: 17.0\n",
      "Run: 398, tot_step: 9264, score: 15.0\n",
      "Run: 399, tot_step: 9279, score: 15.0\n",
      "Run: 400, tot_step: 9303, score: 24.0\n",
      "Run: 401, tot_step: 9313, score: 10.0\n",
      "Run: 402, tot_step: 9386, score: 73.0\n",
      "Run: 403, tot_step: 9401, score: 15.0\n",
      "Run: 404, tot_step: 9417, score: 16.0\n",
      "Run: 405, tot_step: 9464, score: 47.0\n",
      "Run: 406, tot_step: 9491, score: 27.0\n",
      "Run: 407, tot_step: 9505, score: 14.0\n",
      "Run: 408, tot_step: 9517, score: 12.0\n",
      "Run: 409, tot_step: 9550, score: 33.0\n",
      "Run: 410, tot_step: 9568, score: 18.0\n",
      "Run: 411, tot_step: 9603, score: 35.0\n",
      "Run: 412, tot_step: 9625, score: 22.0\n",
      "Run: 413, tot_step: 9647, score: 22.0\n",
      "Run: 414, tot_step: 9660, score: 13.0\n",
      "Run: 415, tot_step: 9675, score: 15.0\n",
      "Run: 416, tot_step: 9698, score: 23.0\n",
      "Run: 417, tot_step: 9707, score: 9.0\n",
      "Run: 418, tot_step: 9723, score: 16.0\n",
      "Run: 419, tot_step: 9800, score: 77.0\n",
      "Run: 420, tot_step: 9815, score: 15.0\n",
      "Run: 421, tot_step: 9832, score: 17.0\n",
      "Run: 422, tot_step: 9853, score: 21.0\n",
      "Run: 423, tot_step: 9871, score: 18.0\n",
      "Run: 424, tot_step: 9897, score: 26.0\n",
      "Run: 425, tot_step: 9912, score: 15.0\n",
      "Run: 426, tot_step: 9938, score: 26.0\n",
      "Run: 427, tot_step: 9956, score: 18.0\n",
      "Run: 428, tot_step: 9969, score: 13.0\n",
      "Run: 429, tot_step: 9981, score: 12.0\n",
      "Run: 430, tot_step: 9994, score: 13.0\n",
      "Run: 431, tot_step: 10016, score: 22.0\n",
      "Run: 432, tot_step: 10050, score: 34.0\n",
      "Run: 433, tot_step: 10066, score: 16.0\n",
      "Run: 434, tot_step: 10080, score: 14.0\n",
      "Run: 435, tot_step: 10098, score: 18.0\n",
      "Run: 436, tot_step: 10114, score: 16.0\n",
      "Run: 437, tot_step: 10140, score: 26.0\n",
      "Run: 438, tot_step: 10155, score: 15.0\n",
      "Run: 439, tot_step: 10186, score: 31.0\n",
      "Run: 440, tot_step: 10200, score: 14.0\n",
      "Run: 441, tot_step: 10209, score: 9.0\n",
      "Run: 442, tot_step: 10228, score: 19.0\n",
      "Run: 443, tot_step: 10247, score: 19.0\n",
      "Run: 444, tot_step: 10297, score: 50.0\n",
      "Run: 445, tot_step: 10320, score: 23.0\n",
      "Run: 446, tot_step: 10340, score: 20.0\n",
      "Run: 447, tot_step: 10385, score: 45.0\n",
      "Run: 448, tot_step: 10415, score: 30.0\n",
      "Run: 449, tot_step: 10445, score: 30.0\n",
      "Run: 450, tot_step: 10480, score: 35.0\n",
      "Run: 451, tot_step: 10523, score: 43.0\n",
      "Run: 452, tot_step: 10553, score: 30.0\n",
      "Run: 453, tot_step: 10577, score: 24.0\n",
      "Run: 454, tot_step: 10587, score: 10.0\n",
      "Run: 455, tot_step: 10609, score: 22.0\n",
      "Run: 456, tot_step: 10623, score: 14.0\n",
      "Run: 457, tot_step: 10633, score: 10.0\n",
      "Run: 458, tot_step: 10653, score: 20.0\n",
      "Run: 459, tot_step: 10666, score: 13.0\n",
      "Run: 460, tot_step: 10687, score: 21.0\n",
      "Run: 461, tot_step: 10709, score: 22.0\n",
      "Run: 462, tot_step: 10725, score: 16.0\n",
      "Run: 463, tot_step: 10765, score: 40.0\n",
      "Run: 464, tot_step: 10791, score: 26.0\n",
      "Run: 465, tot_step: 10810, score: 19.0\n",
      "Run: 466, tot_step: 10831, score: 21.0\n",
      "Run: 467, tot_step: 10846, score: 15.0\n",
      "Run: 468, tot_step: 10862, score: 16.0\n",
      "Run: 469, tot_step: 10873, score: 11.0\n",
      "Run: 470, tot_step: 10887, score: 14.0\n",
      "Run: 471, tot_step: 10913, score: 26.0\n",
      "Run: 472, tot_step: 10922, score: 9.0\n",
      "Run: 473, tot_step: 10934, score: 12.0\n",
      "Run: 474, tot_step: 10968, score: 34.0\n",
      "Run: 475, tot_step: 10981, score: 13.0\n",
      "Run: 476, tot_step: 11004, score: 23.0\n",
      "Run: 477, tot_step: 11027, score: 23.0\n",
      "Run: 478, tot_step: 11048, score: 21.0\n",
      "Run: 479, tot_step: 11065, score: 17.0\n",
      "Run: 480, tot_step: 11082, score: 17.0\n",
      "Run: 481, tot_step: 11093, score: 11.0\n",
      "Run: 482, tot_step: 11109, score: 16.0\n",
      "Run: 483, tot_step: 11135, score: 26.0\n",
      "Run: 484, tot_step: 11158, score: 23.0\n",
      "Run: 485, tot_step: 11181, score: 23.0\n",
      "Run: 486, tot_step: 11198, score: 17.0\n",
      "Run: 487, tot_step: 11209, score: 11.0\n",
      "Run: 488, tot_step: 11245, score: 36.0\n",
      "Run: 489, tot_step: 11260, score: 15.0\n",
      "Run: 490, tot_step: 11283, score: 23.0\n",
      "Run: 491, tot_step: 11306, score: 23.0\n",
      "Run: 492, tot_step: 11334, score: 28.0\n",
      "Run: 493, tot_step: 11375, score: 41.0\n",
      "Run: 494, tot_step: 11390, score: 15.0\n",
      "Run: 495, tot_step: 11402, score: 12.0\n",
      "Run: 496, tot_step: 11425, score: 23.0\n",
      "Run: 497, tot_step: 11435, score: 10.0\n",
      "Run: 498, tot_step: 11491, score: 56.0\n",
      "Run: 499, tot_step: 11500, score: 9.0\n",
      "Run: 500, tot_step: 11523, score: 23.0\n",
      "Run: 501, tot_step: 11535, score: 12.0\n",
      "Run: 502, tot_step: 11547, score: 12.0\n",
      "Run: 503, tot_step: 11592, score: 45.0\n",
      "Run: 504, tot_step: 11615, score: 23.0\n",
      "Run: 505, tot_step: 11666, score: 51.0\n",
      "Run: 506, tot_step: 11686, score: 20.0\n",
      "Run: 507, tot_step: 11736, score: 50.0\n",
      "Run: 508, tot_step: 11748, score: 12.0\n",
      "Run: 509, tot_step: 11765, score: 17.0\n",
      "Run: 510, tot_step: 11795, score: 30.0\n",
      "Run: 511, tot_step: 11805, score: 10.0\n",
      "Run: 512, tot_step: 11822, score: 17.0\n",
      "Run: 513, tot_step: 11856, score: 34.0\n",
      "Run: 514, tot_step: 11873, score: 17.0\n",
      "Run: 515, tot_step: 11909, score: 36.0\n",
      "Run: 516, tot_step: 11920, score: 11.0\n",
      "Run: 517, tot_step: 11945, score: 25.0\n",
      "Run: 518, tot_step: 11961, score: 16.0\n",
      "Run: 519, tot_step: 11975, score: 14.0\n",
      "Run: 520, tot_step: 12011, score: 36.0\n",
      "Run: 521, tot_step: 12021, score: 10.0\n",
      "Run: 522, tot_step: 12049, score: 28.0\n",
      "Run: 523, tot_step: 12081, score: 32.0\n",
      "Run: 524, tot_step: 12095, score: 14.0\n",
      "Run: 525, tot_step: 12127, score: 32.0\n",
      "Run: 526, tot_step: 12143, score: 16.0\n",
      "Run: 527, tot_step: 12153, score: 10.0\n",
      "Run: 528, tot_step: 12187, score: 34.0\n",
      "Run: 529, tot_step: 12198, score: 11.0\n",
      "Run: 530, tot_step: 12219, score: 21.0\n",
      "Run: 531, tot_step: 12237, score: 18.0\n",
      "Run: 532, tot_step: 12275, score: 38.0\n",
      "Run: 533, tot_step: 12295, score: 20.0\n",
      "Run: 534, tot_step: 12325, score: 30.0\n",
      "Run: 535, tot_step: 12341, score: 16.0\n",
      "Run: 536, tot_step: 12350, score: 9.0\n",
      "Run: 537, tot_step: 12361, score: 11.0\n",
      "Run: 538, tot_step: 12373, score: 12.0\n",
      "Run: 539, tot_step: 12385, score: 12.0\n",
      "Run: 540, tot_step: 12410, score: 25.0\n",
      "Run: 541, tot_step: 12436, score: 26.0\n",
      "Run: 542, tot_step: 12448, score: 12.0\n",
      "Run: 543, tot_step: 12465, score: 17.0\n",
      "Run: 544, tot_step: 12490, score: 25.0\n",
      "Run: 545, tot_step: 12512, score: 22.0\n",
      "Run: 546, tot_step: 12529, score: 17.0\n",
      "Run: 547, tot_step: 12568, score: 39.0\n",
      "Run: 548, tot_step: 12661, score: 93.0\n",
      "Run: 549, tot_step: 12679, score: 18.0\n",
      "Run: 550, tot_step: 12694, score: 15.0\n",
      "Run: 551, tot_step: 12738, score: 44.0\n",
      "Run: 552, tot_step: 12752, score: 14.0\n",
      "Run: 553, tot_step: 12763, score: 11.0\n",
      "Run: 554, tot_step: 12778, score: 15.0\n",
      "Run: 555, tot_step: 12790, score: 12.0\n",
      "Run: 556, tot_step: 12818, score: 28.0\n",
      "Run: 557, tot_step: 12853, score: 35.0\n",
      "Run: 558, tot_step: 12864, score: 11.0\n",
      "Run: 559, tot_step: 12889, score: 25.0\n",
      "Run: 560, tot_step: 12902, score: 13.0\n",
      "Run: 561, tot_step: 12914, score: 12.0\n",
      "Run: 562, tot_step: 12955, score: 41.0\n",
      "Run: 563, tot_step: 12979, score: 24.0\n",
      "Run: 564, tot_step: 13017, score: 38.0\n",
      "Run: 565, tot_step: 13029, score: 12.0\n",
      "Run: 566, tot_step: 13040, score: 11.0\n",
      "Run: 567, tot_step: 13065, score: 25.0\n",
      "Run: 568, tot_step: 13082, score: 17.0\n",
      "Run: 569, tot_step: 13102, score: 20.0\n",
      "Run: 570, tot_step: 13115, score: 13.0\n",
      "Run: 571, tot_step: 13127, score: 12.0\n",
      "Run: 572, tot_step: 13146, score: 19.0\n",
      "Run: 573, tot_step: 13167, score: 21.0\n",
      "Run: 574, tot_step: 13193, score: 26.0\n",
      "Run: 575, tot_step: 13204, score: 11.0\n",
      "Run: 576, tot_step: 13239, score: 35.0\n",
      "Run: 577, tot_step: 13253, score: 14.0\n",
      "Run: 578, tot_step: 13292, score: 39.0\n",
      "Run: 579, tot_step: 13308, score: 16.0\n",
      "Run: 580, tot_step: 13354, score: 46.0\n",
      "Run: 581, tot_step: 13369, score: 15.0\n",
      "Run: 582, tot_step: 13421, score: 52.0\n",
      "Run: 583, tot_step: 13435, score: 14.0\n",
      "Run: 584, tot_step: 13493, score: 58.0\n",
      "Run: 585, tot_step: 13509, score: 16.0\n",
      "Run: 586, tot_step: 13530, score: 21.0\n",
      "Run: 587, tot_step: 13550, score: 20.0\n",
      "Run: 588, tot_step: 13575, score: 25.0\n",
      "Run: 589, tot_step: 13594, score: 19.0\n",
      "Run: 590, tot_step: 13626, score: 32.0\n",
      "Run: 591, tot_step: 13651, score: 25.0\n",
      "Run: 592, tot_step: 13662, score: 11.0\n",
      "Run: 593, tot_step: 13675, score: 13.0\n",
      "Run: 594, tot_step: 13704, score: 29.0\n",
      "Run: 595, tot_step: 13722, score: 18.0\n",
      "Run: 596, tot_step: 13740, score: 18.0\n",
      "Run: 597, tot_step: 13760, score: 20.0\n",
      "Run: 598, tot_step: 13813, score: 53.0\n",
      "Run: 599, tot_step: 13835, score: 22.0\n",
      "Run: 600, tot_step: 13849, score: 14.0\n",
      "Run: 601, tot_step: 13876, score: 27.0\n",
      "Run: 602, tot_step: 13927, score: 51.0\n",
      "Run: 603, tot_step: 13944, score: 17.0\n",
      "Run: 604, tot_step: 13974, score: 30.0\n",
      "Run: 605, tot_step: 13988, score: 14.0\n",
      "Run: 606, tot_step: 14018, score: 30.0\n",
      "Run: 607, tot_step: 14038, score: 20.0\n",
      "Run: 608, tot_step: 14055, score: 17.0\n",
      "Run: 609, tot_step: 14064, score: 9.0\n",
      "Run: 610, tot_step: 14088, score: 24.0\n",
      "Run: 611, tot_step: 14106, score: 18.0\n",
      "Run: 612, tot_step: 14128, score: 22.0\n",
      "Run: 613, tot_step: 14149, score: 21.0\n",
      "Run: 614, tot_step: 14172, score: 23.0\n",
      "Run: 615, tot_step: 14188, score: 16.0\n",
      "Run: 616, tot_step: 14202, score: 14.0\n",
      "Run: 617, tot_step: 14217, score: 15.0\n",
      "Run: 618, tot_step: 14238, score: 21.0\n",
      "Run: 619, tot_step: 14257, score: 19.0\n",
      "Run: 620, tot_step: 14266, score: 9.0\n",
      "Run: 621, tot_step: 14276, score: 10.0\n",
      "Run: 622, tot_step: 14298, score: 22.0\n",
      "Run: 623, tot_step: 14312, score: 14.0\n",
      "Run: 624, tot_step: 14325, score: 13.0\n",
      "Run: 625, tot_step: 14341, score: 16.0\n",
      "Run: 626, tot_step: 14370, score: 29.0\n",
      "Run: 627, tot_step: 14385, score: 15.0\n",
      "Run: 628, tot_step: 14403, score: 18.0\n",
      "Run: 629, tot_step: 14418, score: 15.0\n",
      "Run: 630, tot_step: 14440, score: 22.0\n",
      "Run: 631, tot_step: 14493, score: 53.0\n",
      "Run: 632, tot_step: 14506, score: 13.0\n",
      "Run: 633, tot_step: 14521, score: 15.0\n",
      "Run: 634, tot_step: 14536, score: 15.0\n",
      "Run: 635, tot_step: 14563, score: 27.0\n",
      "Run: 636, tot_step: 14593, score: 30.0\n",
      "Run: 637, tot_step: 14607, score: 14.0\n",
      "Run: 638, tot_step: 14618, score: 11.0\n",
      "Run: 639, tot_step: 14636, score: 18.0\n",
      "Run: 640, tot_step: 14671, score: 35.0\n",
      "Run: 641, tot_step: 14692, score: 21.0\n",
      "Run: 642, tot_step: 14745, score: 53.0\n",
      "Run: 643, tot_step: 14764, score: 19.0\n",
      "Run: 644, tot_step: 14788, score: 24.0\n",
      "Run: 645, tot_step: 14813, score: 25.0\n",
      "Run: 646, tot_step: 14835, score: 22.0\n",
      "Run: 647, tot_step: 14857, score: 22.0\n",
      "Run: 648, tot_step: 14876, score: 19.0\n",
      "Run: 649, tot_step: 14914, score: 38.0\n",
      "Run: 650, tot_step: 14934, score: 20.0\n",
      "Run: 651, tot_step: 14953, score: 19.0\n",
      "Run: 652, tot_step: 14970, score: 17.0\n",
      "Run: 653, tot_step: 14982, score: 12.0\n",
      "Run: 654, tot_step: 15006, score: 24.0\n",
      "Run: 655, tot_step: 15051, score: 45.0\n",
      "Run: 656, tot_step: 15076, score: 25.0\n",
      "Run: 657, tot_step: 15118, score: 42.0\n",
      "Run: 658, tot_step: 15136, score: 18.0\n",
      "Run: 659, tot_step: 15148, score: 12.0\n",
      "Run: 660, tot_step: 15173, score: 25.0\n",
      "Run: 661, tot_step: 15191, score: 18.0\n",
      "Run: 662, tot_step: 15202, score: 11.0\n",
      "Run: 663, tot_step: 15221, score: 19.0\n",
      "Run: 664, tot_step: 15246, score: 25.0\n",
      "Run: 665, tot_step: 15258, score: 12.0\n",
      "Run: 666, tot_step: 15292, score: 34.0\n",
      "Run: 667, tot_step: 15317, score: 25.0\n",
      "Run: 668, tot_step: 15333, score: 16.0\n",
      "Run: 669, tot_step: 15345, score: 12.0\n",
      "Run: 670, tot_step: 15372, score: 27.0\n",
      "Run: 671, tot_step: 15403, score: 31.0\n",
      "Run: 672, tot_step: 15415, score: 12.0\n",
      "Run: 673, tot_step: 15439, score: 24.0\n",
      "Run: 674, tot_step: 15454, score: 15.0\n",
      "Run: 675, tot_step: 15478, score: 24.0\n",
      "Run: 676, tot_step: 15504, score: 26.0\n",
      "Run: 677, tot_step: 15517, score: 13.0\n",
      "Run: 678, tot_step: 15539, score: 22.0\n",
      "Run: 679, tot_step: 15604, score: 65.0\n",
      "Run: 680, tot_step: 15620, score: 16.0\n",
      "Run: 681, tot_step: 15632, score: 12.0\n",
      "Run: 682, tot_step: 15656, score: 24.0\n",
      "Run: 683, tot_step: 15675, score: 19.0\n",
      "Run: 684, tot_step: 15689, score: 14.0\n",
      "Run: 685, tot_step: 15700, score: 11.0\n",
      "Run: 686, tot_step: 15711, score: 11.0\n",
      "Run: 687, tot_step: 15727, score: 16.0\n",
      "Run: 688, tot_step: 15745, score: 18.0\n",
      "Run: 689, tot_step: 15756, score: 11.0\n",
      "Run: 690, tot_step: 15768, score: 12.0\n",
      "Run: 691, tot_step: 15779, score: 11.0\n",
      "Run: 692, tot_step: 15794, score: 15.0\n",
      "Run: 693, tot_step: 15814, score: 20.0\n",
      "Run: 694, tot_step: 15852, score: 38.0\n",
      "Run: 695, tot_step: 15888, score: 36.0\n",
      "Run: 696, tot_step: 15911, score: 23.0\n",
      "Run: 697, tot_step: 15932, score: 21.0\n",
      "Run: 698, tot_step: 15948, score: 16.0\n",
      "Run: 699, tot_step: 15962, score: 14.0\n",
      "Run: 700, tot_step: 15972, score: 10.0\n",
      "Run: 701, tot_step: 15989, score: 17.0\n",
      "Run: 702, tot_step: 15999, score: 10.0\n",
      "Run: 703, tot_step: 16034, score: 35.0\n",
      "Run: 704, tot_step: 16059, score: 25.0\n",
      "Run: 705, tot_step: 16070, score: 11.0\n",
      "Run: 706, tot_step: 16102, score: 32.0\n",
      "Run: 707, tot_step: 16114, score: 12.0\n",
      "Run: 708, tot_step: 16142, score: 28.0\n",
      "Run: 709, tot_step: 16153, score: 11.0\n",
      "Run: 710, tot_step: 16166, score: 13.0\n",
      "Run: 711, tot_step: 16189, score: 23.0\n",
      "Run: 712, tot_step: 16216, score: 27.0\n",
      "Run: 713, tot_step: 16240, score: 24.0\n",
      "Run: 714, tot_step: 16275, score: 35.0\n",
      "Run: 715, tot_step: 16291, score: 16.0\n",
      "Run: 716, tot_step: 16301, score: 10.0\n",
      "Run: 717, tot_step: 16358, score: 57.0\n",
      "Run: 718, tot_step: 16410, score: 52.0\n",
      "Run: 719, tot_step: 16425, score: 15.0\n",
      "Run: 720, tot_step: 16478, score: 53.0\n",
      "Run: 721, tot_step: 16489, score: 11.0\n",
      "Run: 722, tot_step: 16506, score: 17.0\n",
      "Run: 723, tot_step: 16564, score: 58.0\n",
      "Run: 724, tot_step: 16584, score: 20.0\n",
      "Run: 725, tot_step: 16616, score: 32.0\n",
      "Run: 726, tot_step: 16633, score: 17.0\n",
      "Run: 727, tot_step: 16648, score: 15.0\n",
      "Run: 728, tot_step: 16671, score: 23.0\n",
      "Run: 729, tot_step: 16685, score: 14.0\n",
      "Run: 730, tot_step: 16714, score: 29.0\n",
      "Run: 731, tot_step: 16734, score: 20.0\n",
      "Run: 732, tot_step: 16757, score: 23.0\n",
      "Run: 733, tot_step: 16769, score: 12.0\n",
      "Run: 734, tot_step: 16806, score: 37.0\n",
      "Run: 735, tot_step: 16851, score: 45.0\n",
      "Run: 736, tot_step: 16867, score: 16.0\n",
      "Run: 737, tot_step: 16900, score: 33.0\n",
      "Run: 738, tot_step: 16910, score: 10.0\n",
      "Run: 739, tot_step: 16923, score: 13.0\n",
      "Run: 740, tot_step: 16938, score: 15.0\n",
      "Run: 741, tot_step: 16951, score: 13.0\n",
      "Run: 742, tot_step: 16964, score: 13.0\n",
      "Run: 743, tot_step: 16988, score: 24.0\n",
      "Run: 744, tot_step: 17007, score: 19.0\n",
      "Run: 745, tot_step: 17027, score: 20.0\n",
      "Run: 746, tot_step: 17055, score: 28.0\n",
      "Run: 747, tot_step: 17089, score: 34.0\n",
      "Run: 748, tot_step: 17097, score: 8.0\n",
      "Run: 749, tot_step: 17123, score: 26.0\n",
      "Run: 750, tot_step: 17160, score: 37.0\n",
      "Run: 751, tot_step: 17174, score: 14.0\n",
      "Run: 752, tot_step: 17187, score: 13.0\n",
      "Run: 753, tot_step: 17196, score: 9.0\n",
      "Run: 754, tot_step: 17209, score: 13.0\n",
      "Run: 755, tot_step: 17221, score: 12.0\n",
      "Run: 756, tot_step: 17257, score: 36.0\n",
      "Run: 757, tot_step: 17277, score: 20.0\n",
      "Run: 758, tot_step: 17293, score: 16.0\n",
      "Run: 759, tot_step: 17312, score: 19.0\n",
      "Run: 760, tot_step: 17351, score: 39.0\n",
      "Run: 761, tot_step: 17370, score: 19.0\n",
      "Run: 762, tot_step: 17385, score: 15.0\n",
      "Run: 763, tot_step: 17418, score: 33.0\n",
      "Run: 764, tot_step: 17465, score: 47.0\n",
      "Run: 765, tot_step: 17478, score: 13.0\n",
      "Run: 766, tot_step: 17502, score: 24.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 767, tot_step: 17540, score: 38.0\n",
      "Run: 768, tot_step: 17615, score: 75.0\n",
      "Run: 769, tot_step: 17628, score: 13.0\n",
      "Run: 770, tot_step: 17664, score: 36.0\n",
      "Run: 771, tot_step: 17694, score: 30.0\n",
      "Run: 772, tot_step: 17728, score: 34.0\n",
      "Run: 773, tot_step: 17743, score: 15.0\n",
      "Run: 774, tot_step: 17780, score: 37.0\n",
      "Run: 775, tot_step: 17802, score: 22.0\n",
      "Run: 776, tot_step: 17816, score: 14.0\n",
      "Run: 777, tot_step: 17829, score: 13.0\n",
      "Run: 778, tot_step: 17841, score: 12.0\n",
      "Run: 779, tot_step: 17866, score: 25.0\n",
      "Run: 780, tot_step: 17887, score: 21.0\n",
      "Run: 781, tot_step: 17906, score: 19.0\n",
      "Run: 782, tot_step: 17924, score: 18.0\n",
      "Run: 783, tot_step: 17938, score: 14.0\n",
      "Run: 784, tot_step: 17947, score: 9.0\n",
      "Run: 785, tot_step: 18002, score: 55.0\n",
      "Run: 786, tot_step: 18034, score: 32.0\n",
      "Run: 787, tot_step: 18057, score: 23.0\n",
      "Run: 788, tot_step: 18074, score: 17.0\n",
      "Run: 789, tot_step: 18089, score: 15.0\n",
      "Run: 790, tot_step: 18109, score: 20.0\n",
      "Run: 791, tot_step: 18131, score: 22.0\n",
      "Run: 792, tot_step: 18149, score: 18.0\n",
      "Run: 793, tot_step: 18166, score: 17.0\n",
      "Run: 794, tot_step: 18204, score: 38.0\n",
      "Run: 795, tot_step: 18225, score: 21.0\n",
      "Run: 796, tot_step: 18241, score: 16.0\n",
      "Run: 797, tot_step: 18262, score: 21.0\n",
      "Run: 798, tot_step: 18316, score: 54.0\n",
      "Run: 799, tot_step: 18349, score: 33.0\n",
      "Run: 800, tot_step: 18371, score: 22.0\n",
      "Run: 801, tot_step: 18393, score: 22.0\n",
      "Run: 802, tot_step: 18406, score: 13.0\n",
      "Run: 803, tot_step: 18428, score: 22.0\n",
      "Run: 804, tot_step: 18445, score: 17.0\n",
      "Run: 805, tot_step: 18456, score: 11.0\n",
      "Run: 806, tot_step: 18479, score: 23.0\n",
      "Run: 807, tot_step: 18503, score: 24.0\n",
      "Run: 808, tot_step: 18515, score: 12.0\n",
      "Run: 809, tot_step: 18526, score: 11.0\n",
      "Run: 810, tot_step: 18545, score: 19.0\n",
      "Run: 811, tot_step: 18567, score: 22.0\n",
      "Run: 812, tot_step: 18587, score: 20.0\n",
      "Run: 813, tot_step: 18601, score: 14.0\n",
      "Run: 814, tot_step: 18631, score: 30.0\n",
      "Run: 815, tot_step: 18668, score: 37.0\n",
      "Run: 816, tot_step: 18678, score: 10.0\n",
      "Run: 817, tot_step: 18697, score: 19.0\n",
      "Run: 818, tot_step: 18737, score: 40.0\n",
      "Run: 819, tot_step: 18766, score: 29.0\n",
      "Run: 820, tot_step: 18789, score: 23.0\n",
      "Run: 821, tot_step: 18801, score: 12.0\n",
      "Run: 822, tot_step: 18820, score: 19.0\n",
      "Run: 823, tot_step: 18829, score: 9.0\n",
      "Run: 824, tot_step: 18863, score: 34.0\n",
      "Run: 825, tot_step: 18875, score: 12.0\n",
      "Run: 826, tot_step: 18888, score: 13.0\n",
      "Run: 827, tot_step: 18920, score: 32.0\n",
      "Run: 828, tot_step: 18941, score: 21.0\n",
      "Run: 829, tot_step: 18968, score: 27.0\n",
      "Run: 830, tot_step: 18994, score: 26.0\n",
      "Run: 831, tot_step: 19010, score: 16.0\n",
      "Run: 832, tot_step: 19024, score: 14.0\n",
      "Run: 833, tot_step: 19036, score: 12.0\n",
      "Run: 834, tot_step: 19068, score: 32.0\n",
      "Run: 835, tot_step: 19082, score: 14.0\n",
      "Run: 836, tot_step: 19125, score: 43.0\n",
      "Run: 837, tot_step: 19136, score: 11.0\n",
      "Run: 838, tot_step: 19160, score: 24.0\n",
      "Run: 839, tot_step: 19208, score: 48.0\n",
      "Run: 840, tot_step: 19236, score: 28.0\n",
      "Run: 841, tot_step: 19247, score: 11.0\n",
      "Run: 842, tot_step: 19266, score: 19.0\n",
      "Run: 843, tot_step: 19291, score: 25.0\n",
      "Run: 844, tot_step: 19303, score: 12.0\n",
      "Run: 845, tot_step: 19318, score: 15.0\n",
      "Run: 846, tot_step: 19330, score: 12.0\n",
      "Run: 847, tot_step: 19340, score: 10.0\n",
      "Run: 848, tot_step: 19349, score: 9.0\n",
      "Run: 849, tot_step: 19363, score: 14.0\n",
      "Run: 850, tot_step: 19393, score: 30.0\n",
      "Run: 851, tot_step: 19443, score: 50.0\n",
      "Run: 852, tot_step: 19463, score: 20.0\n",
      "Run: 853, tot_step: 19482, score: 19.0\n",
      "Run: 854, tot_step: 19501, score: 19.0\n",
      "Run: 855, tot_step: 19521, score: 20.0\n",
      "Run: 856, tot_step: 19541, score: 20.0\n",
      "Run: 857, tot_step: 19554, score: 13.0\n",
      "Run: 858, tot_step: 19571, score: 17.0\n",
      "Run: 859, tot_step: 19586, score: 15.0\n",
      "Run: 860, tot_step: 19604, score: 18.0\n",
      "Run: 861, tot_step: 19634, score: 30.0\n",
      "Run: 862, tot_step: 19651, score: 17.0\n",
      "Run: 863, tot_step: 19665, score: 14.0\n",
      "Run: 864, tot_step: 19679, score: 14.0\n",
      "Run: 865, tot_step: 19703, score: 24.0\n",
      "Run: 866, tot_step: 19726, score: 23.0\n",
      "Run: 867, tot_step: 19763, score: 37.0\n",
      "Run: 868, tot_step: 19778, score: 15.0\n",
      "Run: 869, tot_step: 19791, score: 13.0\n",
      "Run: 870, tot_step: 19810, score: 19.0\n",
      "Run: 871, tot_step: 19821, score: 11.0\n",
      "Run: 872, tot_step: 19831, score: 10.0\n",
      "Run: 873, tot_step: 19848, score: 17.0\n",
      "Run: 874, tot_step: 19870, score: 22.0\n",
      "Run: 875, tot_step: 19883, score: 13.0\n",
      "Run: 876, tot_step: 19894, score: 11.0\n",
      "Run: 877, tot_step: 19914, score: 20.0\n",
      "Run: 878, tot_step: 19926, score: 12.0\n",
      "Run: 879, tot_step: 19963, score: 37.0\n",
      "Run: 880, tot_step: 19994, score: 31.0\n",
      "Run: 881, tot_step: 20016, score: 22.0\n",
      "Run: 882, tot_step: 20042, score: 26.0\n",
      "Run: 883, tot_step: 20057, score: 15.0\n",
      "Run: 884, tot_step: 20066, score: 9.0\n",
      "Run: 885, tot_step: 20113, score: 47.0\n",
      "Run: 886, tot_step: 20125, score: 12.0\n",
      "Run: 887, tot_step: 20145, score: 20.0\n",
      "Run: 888, tot_step: 20157, score: 12.0\n",
      "Run: 889, tot_step: 20170, score: 13.0\n",
      "Run: 890, tot_step: 20181, score: 11.0\n",
      "Run: 891, tot_step: 20197, score: 16.0\n",
      "Run: 892, tot_step: 20212, score: 15.0\n",
      "Run: 893, tot_step: 20232, score: 20.0\n",
      "Run: 894, tot_step: 20263, score: 31.0\n",
      "Run: 895, tot_step: 20275, score: 12.0\n",
      "Run: 896, tot_step: 20353, score: 78.0\n",
      "Run: 897, tot_step: 20375, score: 22.0\n",
      "Run: 898, tot_step: 20397, score: 22.0\n",
      "Run: 899, tot_step: 20413, score: 16.0\n",
      "Run: 900, tot_step: 20433, score: 20.0\n",
      "Run: 901, tot_step: 20454, score: 21.0\n",
      "Run: 902, tot_step: 20466, score: 12.0\n",
      "Run: 903, tot_step: 20494, score: 28.0\n",
      "Run: 904, tot_step: 20517, score: 23.0\n",
      "Run: 905, tot_step: 20585, score: 68.0\n",
      "Run: 906, tot_step: 20597, score: 12.0\n",
      "Run: 907, tot_step: 20623, score: 26.0\n",
      "Run: 908, tot_step: 20639, score: 16.0\n",
      "Run: 909, tot_step: 20665, score: 26.0\n",
      "Run: 910, tot_step: 20688, score: 23.0\n",
      "Run: 911, tot_step: 20713, score: 25.0\n",
      "Run: 912, tot_step: 20732, score: 19.0\n",
      "Run: 913, tot_step: 20757, score: 25.0\n",
      "Run: 914, tot_step: 20777, score: 20.0\n",
      "Run: 915, tot_step: 20792, score: 15.0\n",
      "Run: 916, tot_step: 20810, score: 18.0\n",
      "Run: 917, tot_step: 20839, score: 29.0\n",
      "Run: 918, tot_step: 20849, score: 10.0\n",
      "Run: 919, tot_step: 20864, score: 15.0\n",
      "Run: 920, tot_step: 20881, score: 17.0\n",
      "Run: 921, tot_step: 20904, score: 23.0\n",
      "Run: 922, tot_step: 20929, score: 25.0\n",
      "Run: 923, tot_step: 20940, score: 11.0\n",
      "Run: 924, tot_step: 20975, score: 35.0\n",
      "Run: 925, tot_step: 20987, score: 12.0\n",
      "Run: 926, tot_step: 21003, score: 16.0\n",
      "Run: 927, tot_step: 21019, score: 16.0\n",
      "Run: 928, tot_step: 21038, score: 19.0\n",
      "Run: 929, tot_step: 21053, score: 15.0\n",
      "Run: 930, tot_step: 21067, score: 14.0\n",
      "Run: 931, tot_step: 21079, score: 12.0\n",
      "Run: 932, tot_step: 21144, score: 65.0\n",
      "Run: 933, tot_step: 21166, score: 22.0\n",
      "Run: 934, tot_step: 21182, score: 16.0\n",
      "Run: 935, tot_step: 21209, score: 27.0\n",
      "Run: 936, tot_step: 21234, score: 25.0\n",
      "Run: 937, tot_step: 21250, score: 16.0\n",
      "Run: 938, tot_step: 21274, score: 24.0\n",
      "Run: 939, tot_step: 21318, score: 44.0\n",
      "Run: 940, tot_step: 21330, score: 12.0\n",
      "Run: 941, tot_step: 21349, score: 19.0\n",
      "Run: 942, tot_step: 21369, score: 20.0\n",
      "Run: 943, tot_step: 21392, score: 23.0\n",
      "Run: 944, tot_step: 21438, score: 46.0\n",
      "Run: 945, tot_step: 21456, score: 18.0\n",
      "Run: 946, tot_step: 21473, score: 17.0\n",
      "Run: 947, tot_step: 21493, score: 20.0\n",
      "Run: 948, tot_step: 21523, score: 30.0\n",
      "Run: 949, tot_step: 21541, score: 18.0\n",
      "Run: 950, tot_step: 21565, score: 24.0\n",
      "Run: 951, tot_step: 21588, score: 23.0\n",
      "Run: 952, tot_step: 21607, score: 19.0\n",
      "Run: 953, tot_step: 21619, score: 12.0\n",
      "Run: 954, tot_step: 21649, score: 30.0\n",
      "Run: 955, tot_step: 21666, score: 17.0\n",
      "Run: 956, tot_step: 21702, score: 36.0\n",
      "Run: 957, tot_step: 21716, score: 14.0\n",
      "Run: 958, tot_step: 21740, score: 24.0\n",
      "Run: 959, tot_step: 21814, score: 74.0\n",
      "Run: 960, tot_step: 21829, score: 15.0\n",
      "Run: 961, tot_step: 21857, score: 28.0\n",
      "Run: 962, tot_step: 21875, score: 18.0\n",
      "Run: 963, tot_step: 21924, score: 49.0\n",
      "Run: 964, tot_step: 21968, score: 44.0\n",
      "Run: 965, tot_step: 21983, score: 15.0\n",
      "Run: 966, tot_step: 21993, score: 10.0\n",
      "Run: 967, tot_step: 22012, score: 19.0\n",
      "Run: 968, tot_step: 22029, score: 17.0\n",
      "Run: 969, tot_step: 22040, score: 11.0\n",
      "Run: 970, tot_step: 22054, score: 14.0\n",
      "Run: 971, tot_step: 22067, score: 13.0\n",
      "Run: 972, tot_step: 22077, score: 10.0\n",
      "Run: 973, tot_step: 22105, score: 28.0\n",
      "Run: 974, tot_step: 22116, score: 11.0\n",
      "Run: 975, tot_step: 22128, score: 12.0\n",
      "Run: 976, tot_step: 22142, score: 14.0\n",
      "Run: 977, tot_step: 22159, score: 17.0\n",
      "Run: 978, tot_step: 22181, score: 22.0\n",
      "Run: 979, tot_step: 22233, score: 52.0\n",
      "Run: 980, tot_step: 22263, score: 30.0\n",
      "Run: 981, tot_step: 22294, score: 31.0\n",
      "Run: 982, tot_step: 22327, score: 33.0\n",
      "Run: 983, tot_step: 22341, score: 14.0\n",
      "Run: 984, tot_step: 22363, score: 22.0\n",
      "Run: 985, tot_step: 22436, score: 73.0\n",
      "Run: 986, tot_step: 22456, score: 20.0\n",
      "Run: 987, tot_step: 22469, score: 13.0\n",
      "Run: 988, tot_step: 22487, score: 18.0\n",
      "Run: 989, tot_step: 22514, score: 27.0\n",
      "Run: 990, tot_step: 22534, score: 20.0\n",
      "Run: 991, tot_step: 22561, score: 27.0\n",
      "Run: 992, tot_step: 22570, score: 9.0\n",
      "Run: 993, tot_step: 22600, score: 30.0\n",
      "Run: 994, tot_step: 22614, score: 14.0\n",
      "Run: 995, tot_step: 22639, score: 25.0\n",
      "Run: 996, tot_step: 22656, score: 17.0\n",
      "Run: 997, tot_step: 22682, score: 26.0\n",
      "Run: 998, tot_step: 22700, score: 18.0\n",
      "Run: 999, tot_step: 22747, score: 47.0\n",
      "Run: 1000, tot_step: 22759, score: 12.0\n",
      "Run: 1001, tot_step: 22775, score: 16.0\n",
      "Run: 1002, tot_step: 22806, score: 31.0\n",
      "Run: 1003, tot_step: 22829, score: 23.0\n",
      "Run: 1004, tot_step: 22859, score: 30.0\n",
      "Run: 1005, tot_step: 22869, score: 10.0\n",
      "Run: 1006, tot_step: 22888, score: 19.0\n",
      "Run: 1007, tot_step: 22898, score: 10.0\n",
      "Run: 1008, tot_step: 22922, score: 24.0\n",
      "Run: 1009, tot_step: 22947, score: 25.0\n",
      "Run: 1010, tot_step: 23004, score: 57.0\n",
      "Run: 1011, tot_step: 23053, score: 49.0\n",
      "Run: 1012, tot_step: 23082, score: 29.0\n",
      "Run: 1013, tot_step: 23121, score: 39.0\n",
      "Run: 1014, tot_step: 23152, score: 31.0\n",
      "Run: 1015, tot_step: 23179, score: 27.0\n",
      "Run: 1016, tot_step: 23196, score: 17.0\n",
      "Run: 1017, tot_step: 23213, score: 17.0\n",
      "Run: 1018, tot_step: 23225, score: 12.0\n",
      "Run: 1019, tot_step: 23245, score: 20.0\n",
      "Run: 1020, tot_step: 23258, score: 13.0\n",
      "Run: 1021, tot_step: 23271, score: 13.0\n",
      "Run: 1022, tot_step: 23283, score: 12.0\n",
      "Run: 1023, tot_step: 23302, score: 19.0\n",
      "Run: 1024, tot_step: 23333, score: 31.0\n",
      "Run: 1025, tot_step: 23352, score: 19.0\n",
      "Run: 1026, tot_step: 23377, score: 25.0\n",
      "Run: 1027, tot_step: 23390, score: 13.0\n",
      "Run: 1028, tot_step: 23409, score: 19.0\n",
      "Run: 1029, tot_step: 23424, score: 15.0\n",
      "Run: 1030, tot_step: 23487, score: 63.0\n",
      "Run: 1031, tot_step: 23508, score: 21.0\n",
      "Run: 1032, tot_step: 23523, score: 15.0\n",
      "Run: 1033, tot_step: 23538, score: 15.0\n",
      "Run: 1034, tot_step: 23590, score: 52.0\n",
      "Run: 1035, tot_step: 23604, score: 14.0\n",
      "Run: 1036, tot_step: 23623, score: 19.0\n",
      "Run: 1037, tot_step: 23654, score: 31.0\n",
      "Run: 1038, tot_step: 23689, score: 35.0\n",
      "Run: 1039, tot_step: 23713, score: 24.0\n",
      "Run: 1040, tot_step: 23752, score: 39.0\n",
      "Run: 1041, tot_step: 23763, score: 11.0\n",
      "Run: 1042, tot_step: 23782, score: 19.0\n",
      "Run: 1043, tot_step: 23815, score: 33.0\n",
      "Run: 1044, tot_step: 23830, score: 15.0\n",
      "Run: 1045, tot_step: 23841, score: 11.0\n",
      "Run: 1046, tot_step: 23863, score: 22.0\n",
      "Run: 1047, tot_step: 23884, score: 21.0\n",
      "Run: 1048, tot_step: 23895, score: 11.0\n",
      "Run: 1049, tot_step: 23908, score: 13.0\n",
      "Run: 1050, tot_step: 23919, score: 11.0\n",
      "Run: 1051, tot_step: 23940, score: 21.0\n",
      "Run: 1052, tot_step: 23956, score: 16.0\n",
      "Run: 1053, tot_step: 23973, score: 17.0\n",
      "Run: 1054, tot_step: 23987, score: 14.0\n",
      "Run: 1055, tot_step: 24016, score: 29.0\n",
      "Run: 1056, tot_step: 24044, score: 28.0\n",
      "Run: 1057, tot_step: 24067, score: 23.0\n",
      "Run: 1058, tot_step: 24096, score: 29.0\n",
      "Run: 1059, tot_step: 24121, score: 25.0\n",
      "Run: 1060, tot_step: 24134, score: 13.0\n",
      "Run: 1061, tot_step: 24151, score: 17.0\n",
      "Run: 1062, tot_step: 24162, score: 11.0\n",
      "Run: 1063, tot_step: 24191, score: 29.0\n",
      "Run: 1064, tot_step: 24214, score: 23.0\n",
      "Run: 1065, tot_step: 24233, score: 19.0\n",
      "Run: 1066, tot_step: 24289, score: 56.0\n",
      "Run: 1067, tot_step: 24302, score: 13.0\n",
      "Run: 1068, tot_step: 24342, score: 40.0\n",
      "Run: 1069, tot_step: 24389, score: 47.0\n",
      "Run: 1070, tot_step: 24407, score: 18.0\n",
      "Run: 1071, tot_step: 24425, score: 18.0\n",
      "Run: 1072, tot_step: 24479, score: 54.0\n",
      "Run: 1073, tot_step: 24505, score: 26.0\n",
      "Run: 1074, tot_step: 24519, score: 14.0\n",
      "Run: 1075, tot_step: 24534, score: 15.0\n",
      "Run: 1076, tot_step: 24554, score: 20.0\n",
      "Run: 1077, tot_step: 24589, score: 35.0\n",
      "Run: 1078, tot_step: 24607, score: 18.0\n",
      "Run: 1079, tot_step: 24623, score: 16.0\n",
      "Run: 1080, tot_step: 24634, score: 11.0\n",
      "Run: 1081, tot_step: 24665, score: 31.0\n",
      "Run: 1082, tot_step: 24713, score: 48.0\n",
      "Run: 1083, tot_step: 24731, score: 18.0\n",
      "Run: 1084, tot_step: 24747, score: 16.0\n",
      "Run: 1085, tot_step: 24759, score: 12.0\n",
      "Run: 1086, tot_step: 24773, score: 14.0\n",
      "Run: 1087, tot_step: 24784, score: 11.0\n",
      "Run: 1088, tot_step: 24829, score: 45.0\n",
      "Run: 1089, tot_step: 24844, score: 15.0\n",
      "Run: 1090, tot_step: 24862, score: 18.0\n",
      "Run: 1091, tot_step: 24880, score: 18.0\n",
      "Run: 1092, tot_step: 24924, score: 44.0\n",
      "Run: 1093, tot_step: 24940, score: 16.0\n",
      "Run: 1094, tot_step: 24958, score: 18.0\n",
      "Run: 1095, tot_step: 24968, score: 10.0\n",
      "Run: 1096, tot_step: 24993, score: 25.0\n",
      "Run: 1097, tot_step: 25005, score: 12.0\n",
      "Run: 1098, tot_step: 25019, score: 14.0\n",
      "Run: 1099, tot_step: 25040, score: 21.0\n",
      "Run: 1100, tot_step: 25058, score: 18.0\n",
      "Run: 1101, tot_step: 25071, score: 13.0\n",
      "Run: 1102, tot_step: 25083, score: 12.0\n",
      "Run: 1103, tot_step: 25106, score: 23.0\n",
      "Run: 1104, tot_step: 25187, score: 81.0\n",
      "Run: 1105, tot_step: 25225, score: 38.0\n",
      "Run: 1106, tot_step: 25253, score: 28.0\n",
      "Run: 1107, tot_step: 25272, score: 19.0\n",
      "Run: 1108, tot_step: 25289, score: 17.0\n",
      "Run: 1109, tot_step: 25302, score: 13.0\n",
      "Run: 1110, tot_step: 25322, score: 20.0\n",
      "Run: 1111, tot_step: 25336, score: 14.0\n",
      "Run: 1112, tot_step: 25350, score: 14.0\n",
      "Run: 1113, tot_step: 25360, score: 10.0\n",
      "Run: 1114, tot_step: 25406, score: 46.0\n",
      "Run: 1115, tot_step: 25420, score: 14.0\n",
      "Run: 1116, tot_step: 25432, score: 12.0\n",
      "Run: 1117, tot_step: 25448, score: 16.0\n",
      "Run: 1118, tot_step: 25468, score: 20.0\n",
      "Run: 1119, tot_step: 25480, score: 12.0\n",
      "Run: 1120, tot_step: 25493, score: 13.0\n",
      "Run: 1121, tot_step: 25518, score: 25.0\n",
      "Run: 1122, tot_step: 25571, score: 53.0\n",
      "Run: 1123, tot_step: 25627, score: 56.0\n",
      "Run: 1124, tot_step: 25684, score: 57.0\n",
      "Run: 1125, tot_step: 25698, score: 14.0\n",
      "Run: 1126, tot_step: 25723, score: 25.0\n",
      "Run: 1127, tot_step: 25740, score: 17.0\n",
      "Run: 1128, tot_step: 25762, score: 22.0\n",
      "Run: 1129, tot_step: 25787, score: 25.0\n",
      "Run: 1130, tot_step: 25807, score: 20.0\n",
      "Run: 1131, tot_step: 25828, score: 21.0\n",
      "Run: 1132, tot_step: 25879, score: 51.0\n",
      "Run: 1133, tot_step: 25894, score: 15.0\n",
      "Run: 1134, tot_step: 25921, score: 27.0\n",
      "Run: 1135, tot_step: 25955, score: 34.0\n",
      "Run: 1136, tot_step: 25989, score: 34.0\n",
      "Run: 1137, tot_step: 26004, score: 15.0\n",
      "Run: 1138, tot_step: 26021, score: 17.0\n",
      "Run: 1139, tot_step: 26060, score: 39.0\n",
      "Run: 1140, tot_step: 26081, score: 21.0\n",
      "Run: 1141, tot_step: 26107, score: 26.0\n",
      "Run: 1142, tot_step: 26121, score: 14.0\n",
      "Run: 1143, tot_step: 26162, score: 41.0\n",
      "Run: 1144, tot_step: 26189, score: 27.0\n",
      "Run: 1145, tot_step: 26221, score: 32.0\n",
      "Run: 1146, tot_step: 26249, score: 28.0\n",
      "Run: 1147, tot_step: 26261, score: 12.0\n",
      "Run: 1148, tot_step: 26306, score: 45.0\n",
      "Run: 1149, tot_step: 26332, score: 26.0\n",
      "Run: 1150, tot_step: 26362, score: 30.0\n",
      "Run: 1151, tot_step: 26389, score: 27.0\n",
      "Run: 1152, tot_step: 26414, score: 25.0\n",
      "Run: 1153, tot_step: 26427, score: 13.0\n",
      "Run: 1154, tot_step: 26446, score: 19.0\n",
      "Run: 1155, tot_step: 26456, score: 10.0\n",
      "Run: 1156, tot_step: 26499, score: 43.0\n",
      "Run: 1157, tot_step: 26534, score: 35.0\n",
      "Run: 1158, tot_step: 26555, score: 21.0\n",
      "Run: 1159, tot_step: 26582, score: 27.0\n",
      "Run: 1160, tot_step: 26596, score: 14.0\n",
      "Run: 1161, tot_step: 26607, score: 11.0\n",
      "Run: 1162, tot_step: 26627, score: 20.0\n",
      "Run: 1163, tot_step: 26645, score: 18.0\n",
      "Run: 1164, tot_step: 26660, score: 15.0\n",
      "Run: 1165, tot_step: 26672, score: 12.0\n",
      "Run: 1166, tot_step: 26696, score: 24.0\n",
      "Run: 1167, tot_step: 26723, score: 27.0\n",
      "Run: 1168, tot_step: 26752, score: 29.0\n",
      "Run: 1169, tot_step: 26789, score: 37.0\n",
      "Run: 1170, tot_step: 26816, score: 27.0\n",
      "Run: 1171, tot_step: 26836, score: 20.0\n",
      "Run: 1172, tot_step: 26847, score: 11.0\n",
      "Run: 1173, tot_step: 26877, score: 30.0\n",
      "Run: 1174, tot_step: 26909, score: 32.0\n",
      "Run: 1175, tot_step: 26926, score: 17.0\n",
      "Run: 1176, tot_step: 26937, score: 11.0\n",
      "Run: 1177, tot_step: 26958, score: 21.0\n",
      "Run: 1178, tot_step: 27026, score: 68.0\n",
      "Run: 1179, tot_step: 27067, score: 41.0\n",
      "Run: 1180, tot_step: 27085, score: 18.0\n",
      "Run: 1181, tot_step: 27113, score: 28.0\n",
      "Run: 1182, tot_step: 27172, score: 59.0\n",
      "Run: 1183, tot_step: 27190, score: 18.0\n",
      "Run: 1184, tot_step: 27209, score: 19.0\n",
      "Run: 1185, tot_step: 27229, score: 20.0\n",
      "Run: 1186, tot_step: 27241, score: 12.0\n",
      "Run: 1187, tot_step: 27263, score: 22.0\n",
      "Run: 1188, tot_step: 27274, score: 11.0\n",
      "Run: 1189, tot_step: 27290, score: 16.0\n",
      "Run: 1190, tot_step: 27303, score: 13.0\n",
      "Run: 1191, tot_step: 27321, score: 18.0\n",
      "Run: 1192, tot_step: 27354, score: 33.0\n",
      "Run: 1193, tot_step: 27380, score: 26.0\n",
      "Run: 1194, tot_step: 27402, score: 22.0\n",
      "Run: 1195, tot_step: 27414, score: 12.0\n",
      "Run: 1196, tot_step: 27449, score: 35.0\n",
      "Run: 1197, tot_step: 27461, score: 12.0\n",
      "Run: 1198, tot_step: 27484, score: 23.0\n",
      "Run: 1199, tot_step: 27494, score: 10.0\n",
      "Run: 1200, tot_step: 27513, score: 19.0\n",
      "Run: 1201, tot_step: 27566, score: 53.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1202, tot_step: 27610, score: 44.0\n",
      "Run: 1203, tot_step: 27628, score: 18.0\n",
      "Run: 1204, tot_step: 27669, score: 41.0\n",
      "Run: 1205, tot_step: 27679, score: 10.0\n",
      "Run: 1206, tot_step: 27708, score: 29.0\n",
      "Run: 1207, tot_step: 27731, score: 23.0\n",
      "Run: 1208, tot_step: 27750, score: 19.0\n",
      "Run: 1209, tot_step: 27763, score: 13.0\n",
      "Run: 1210, tot_step: 27773, score: 10.0\n",
      "Run: 1211, tot_step: 27818, score: 45.0\n",
      "Run: 1212, tot_step: 27839, score: 21.0\n",
      "Run: 1213, tot_step: 27856, score: 17.0\n",
      "Run: 1214, tot_step: 27916, score: 60.0\n",
      "Run: 1215, tot_step: 27932, score: 16.0\n",
      "Run: 1216, tot_step: 27946, score: 14.0\n",
      "Run: 1217, tot_step: 27965, score: 19.0\n",
      "Run: 1218, tot_step: 27975, score: 10.0\n",
      "Run: 1219, tot_step: 27986, score: 11.0\n",
      "Run: 1220, tot_step: 27998, score: 12.0\n",
      "Run: 1221, tot_step: 28031, score: 33.0\n",
      "Run: 1222, tot_step: 28048, score: 17.0\n",
      "Run: 1223, tot_step: 28058, score: 10.0\n",
      "Run: 1224, tot_step: 28075, score: 17.0\n",
      "Run: 1225, tot_step: 28094, score: 19.0\n",
      "Run: 1226, tot_step: 28103, score: 9.0\n",
      "Run: 1227, tot_step: 28125, score: 22.0\n",
      "Run: 1228, tot_step: 28141, score: 16.0\n",
      "Run: 1229, tot_step: 28168, score: 27.0\n",
      "Run: 1230, tot_step: 28212, score: 44.0\n",
      "Run: 1231, tot_step: 28228, score: 16.0\n",
      "Run: 1232, tot_step: 28246, score: 18.0\n",
      "Run: 1233, tot_step: 28262, score: 16.0\n",
      "Run: 1234, tot_step: 28287, score: 25.0\n",
      "Run: 1235, tot_step: 28312, score: 25.0\n",
      "Run: 1236, tot_step: 28324, score: 12.0\n",
      "Run: 1237, tot_step: 28364, score: 40.0\n",
      "Run: 1238, tot_step: 28376, score: 12.0\n",
      "Run: 1239, tot_step: 28402, score: 26.0\n",
      "Run: 1240, tot_step: 28419, score: 17.0\n",
      "Run: 1241, tot_step: 28438, score: 19.0\n",
      "Run: 1242, tot_step: 28451, score: 13.0\n",
      "Run: 1243, tot_step: 28483, score: 32.0\n",
      "Run: 1244, tot_step: 28503, score: 20.0\n",
      "Run: 1245, tot_step: 28524, score: 21.0\n",
      "Run: 1246, tot_step: 28551, score: 27.0\n",
      "Run: 1247, tot_step: 28568, score: 17.0\n",
      "Run: 1248, tot_step: 28586, score: 18.0\n",
      "Run: 1249, tot_step: 28606, score: 20.0\n",
      "Run: 1250, tot_step: 28624, score: 18.0\n",
      "Run: 1251, tot_step: 28635, score: 11.0\n",
      "Run: 1252, tot_step: 28648, score: 13.0\n",
      "Run: 1253, tot_step: 28659, score: 11.0\n",
      "Run: 1254, tot_step: 28680, score: 21.0\n",
      "Run: 1255, tot_step: 28699, score: 19.0\n",
      "Run: 1256, tot_step: 28730, score: 31.0\n",
      "Run: 1257, tot_step: 28754, score: 24.0\n",
      "Run: 1258, tot_step: 28771, score: 17.0\n",
      "Run: 1259, tot_step: 28784, score: 13.0\n",
      "Run: 1260, tot_step: 28797, score: 13.0\n",
      "Run: 1261, tot_step: 28810, score: 13.0\n",
      "Run: 1262, tot_step: 28824, score: 14.0\n",
      "Run: 1263, tot_step: 28846, score: 22.0\n",
      "Run: 1264, tot_step: 28863, score: 17.0\n",
      "Run: 1265, tot_step: 28907, score: 44.0\n",
      "Run: 1266, tot_step: 28920, score: 13.0\n",
      "Run: 1267, tot_step: 28947, score: 27.0\n",
      "Run: 1268, tot_step: 28963, score: 16.0\n",
      "Run: 1269, tot_step: 28981, score: 18.0\n",
      "Run: 1270, tot_step: 29066, score: 85.0\n",
      "Run: 1271, tot_step: 29082, score: 16.0\n",
      "Run: 1272, tot_step: 29092, score: 10.0\n",
      "Run: 1273, tot_step: 29111, score: 19.0\n",
      "Run: 1274, tot_step: 29131, score: 20.0\n",
      "Run: 1275, tot_step: 29146, score: 15.0\n",
      "Run: 1276, tot_step: 29159, score: 13.0\n",
      "Run: 1277, tot_step: 29175, score: 16.0\n",
      "Run: 1278, tot_step: 29189, score: 14.0\n",
      "Run: 1279, tot_step: 29202, score: 13.0\n",
      "Run: 1280, tot_step: 29213, score: 11.0\n",
      "Run: 1281, tot_step: 29228, score: 15.0\n",
      "Run: 1282, tot_step: 29243, score: 15.0\n",
      "Run: 1283, tot_step: 29261, score: 18.0\n",
      "Run: 1284, tot_step: 29280, score: 19.0\n",
      "Run: 1285, tot_step: 29290, score: 10.0\n",
      "Run: 1286, tot_step: 29307, score: 17.0\n",
      "Run: 1287, tot_step: 29324, score: 17.0\n",
      "Run: 1288, tot_step: 29354, score: 30.0\n",
      "Run: 1289, tot_step: 29370, score: 16.0\n",
      "Run: 1290, tot_step: 29382, score: 12.0\n",
      "Run: 1291, tot_step: 29395, score: 13.0\n",
      "Run: 1292, tot_step: 29422, score: 27.0\n",
      "Run: 1293, tot_step: 29442, score: 20.0\n",
      "Run: 1294, tot_step: 29456, score: 14.0\n",
      "Run: 1295, tot_step: 29469, score: 13.0\n",
      "Run: 1296, tot_step: 29504, score: 35.0\n",
      "Run: 1297, tot_step: 29515, score: 11.0\n",
      "Run: 1298, tot_step: 29531, score: 16.0\n",
      "Run: 1299, tot_step: 29545, score: 14.0\n",
      "Run: 1300, tot_step: 29561, score: 16.0\n",
      "Run: 1301, tot_step: 29581, score: 20.0\n",
      "Run: 1302, tot_step: 29597, score: 16.0\n",
      "Run: 1303, tot_step: 29611, score: 14.0\n",
      "Run: 1304, tot_step: 29677, score: 66.0\n",
      "Run: 1305, tot_step: 29721, score: 44.0\n",
      "Run: 1306, tot_step: 29756, score: 35.0\n",
      "Run: 1307, tot_step: 29769, score: 13.0\n",
      "Run: 1308, tot_step: 29789, score: 20.0\n",
      "Run: 1309, tot_step: 29801, score: 12.0\n",
      "Run: 1310, tot_step: 29814, score: 13.0\n",
      "Run: 1311, tot_step: 29844, score: 30.0\n",
      "Run: 1312, tot_step: 29864, score: 20.0\n",
      "Run: 1313, tot_step: 29874, score: 10.0\n",
      "Run: 1314, tot_step: 29889, score: 15.0\n",
      "Run: 1315, tot_step: 29912, score: 23.0\n",
      "Run: 1316, tot_step: 29942, score: 30.0\n",
      "Run: 1317, tot_step: 29974, score: 32.0\n",
      "Run: 1318, tot_step: 29993, score: 19.0\n",
      "Run: 1319, tot_step: 30017, score: 24.0\n",
      "Run: 1320, tot_step: 30053, score: 36.0\n",
      "Run: 1321, tot_step: 30105, score: 52.0\n",
      "Run: 1322, tot_step: 30121, score: 16.0\n",
      "Run: 1323, tot_step: 30154, score: 33.0\n",
      "Run: 1324, tot_step: 30178, score: 24.0\n",
      "Run: 1325, tot_step: 30197, score: 19.0\n",
      "Run: 1326, tot_step: 30237, score: 40.0\n",
      "Run: 1327, tot_step: 30258, score: 21.0\n",
      "Run: 1328, tot_step: 30287, score: 29.0\n",
      "Run: 1329, tot_step: 30300, score: 13.0\n",
      "Run: 1330, tot_step: 30311, score: 11.0\n",
      "Run: 1331, tot_step: 30346, score: 35.0\n",
      "Run: 1332, tot_step: 30373, score: 27.0\n",
      "Run: 1333, tot_step: 30393, score: 20.0\n",
      "Run: 1334, tot_step: 30422, score: 29.0\n",
      "Run: 1335, tot_step: 30439, score: 17.0\n",
      "Run: 1336, tot_step: 30480, score: 41.0\n",
      "Run: 1337, tot_step: 30501, score: 21.0\n",
      "Run: 1338, tot_step: 30514, score: 13.0\n",
      "Run: 1339, tot_step: 30528, score: 14.0\n",
      "Run: 1340, tot_step: 30547, score: 19.0\n",
      "Run: 1341, tot_step: 30561, score: 14.0\n",
      "Run: 1342, tot_step: 30572, score: 11.0\n",
      "Run: 1343, tot_step: 30603, score: 31.0\n",
      "Run: 1344, tot_step: 30612, score: 9.0\n",
      "Run: 1345, tot_step: 30658, score: 46.0\n",
      "Run: 1346, tot_step: 30670, score: 12.0\n",
      "Run: 1347, tot_step: 30687, score: 17.0\n",
      "Run: 1348, tot_step: 30697, score: 10.0\n",
      "Run: 1349, tot_step: 30722, score: 25.0\n",
      "Run: 1350, tot_step: 30764, score: 42.0\n",
      "Run: 1351, tot_step: 30796, score: 32.0\n",
      "Run: 1352, tot_step: 30820, score: 24.0\n",
      "Run: 1353, tot_step: 30872, score: 52.0\n",
      "Run: 1354, tot_step: 30946, score: 74.0\n",
      "Run: 1355, tot_step: 30992, score: 46.0\n",
      "Run: 1356, tot_step: 31009, score: 17.0\n",
      "Run: 1357, tot_step: 31060, score: 51.0\n",
      "Run: 1358, tot_step: 31080, score: 20.0\n",
      "Run: 1359, tot_step: 31106, score: 26.0\n",
      "Run: 1360, tot_step: 31172, score: 66.0\n",
      "Run: 1361, tot_step: 31199, score: 27.0\n",
      "Run: 1362, tot_step: 31235, score: 36.0\n",
      "Run: 1363, tot_step: 31253, score: 18.0\n",
      "Run: 1364, tot_step: 31266, score: 13.0\n",
      "Run: 1365, tot_step: 31280, score: 14.0\n",
      "Run: 1366, tot_step: 31292, score: 12.0\n",
      "Run: 1367, tot_step: 31307, score: 15.0\n",
      "Run: 1368, tot_step: 31346, score: 39.0\n",
      "Run: 1369, tot_step: 31359, score: 13.0\n",
      "Run: 1370, tot_step: 31379, score: 20.0\n",
      "Run: 1371, tot_step: 31427, score: 48.0\n",
      "Run: 1372, tot_step: 31440, score: 13.0\n",
      "Run: 1373, tot_step: 31450, score: 10.0\n",
      "Run: 1374, tot_step: 31463, score: 13.0\n",
      "Run: 1375, tot_step: 31511, score: 48.0\n",
      "Run: 1376, tot_step: 31532, score: 21.0\n",
      "Run: 1377, tot_step: 31557, score: 25.0\n",
      "Run: 1378, tot_step: 31573, score: 16.0\n",
      "Run: 1379, tot_step: 31586, score: 13.0\n",
      "Run: 1380, tot_step: 31629, score: 43.0\n",
      "Run: 1381, tot_step: 31652, score: 23.0\n",
      "Run: 1382, tot_step: 31663, score: 11.0\n",
      "Run: 1383, tot_step: 31672, score: 9.0\n",
      "Run: 1384, tot_step: 31703, score: 31.0\n",
      "Run: 1385, tot_step: 31736, score: 33.0\n",
      "Run: 1386, tot_step: 31760, score: 24.0\n",
      "Run: 1387, tot_step: 31777, score: 17.0\n",
      "Run: 1388, tot_step: 31795, score: 18.0\n",
      "Run: 1389, tot_step: 31814, score: 19.0\n",
      "Run: 1390, tot_step: 31823, score: 9.0\n",
      "Run: 1391, tot_step: 31837, score: 14.0\n",
      "Run: 1392, tot_step: 31858, score: 21.0\n",
      "Run: 1393, tot_step: 31876, score: 18.0\n",
      "Run: 1394, tot_step: 31890, score: 14.0\n",
      "Run: 1395, tot_step: 31941, score: 51.0\n",
      "Run: 1396, tot_step: 31955, score: 14.0\n",
      "Run: 1397, tot_step: 31967, score: 12.0\n",
      "Run: 1398, tot_step: 31980, score: 13.0\n",
      "Run: 1399, tot_step: 31995, score: 15.0\n",
      "Run: 1400, tot_step: 32015, score: 20.0\n",
      "Run: 1401, tot_step: 32030, score: 15.0\n",
      "Run: 1402, tot_step: 32068, score: 38.0\n",
      "Run: 1403, tot_step: 32084, score: 16.0\n",
      "Run: 1404, tot_step: 32110, score: 26.0\n",
      "Run: 1405, tot_step: 32155, score: 45.0\n",
      "Run: 1406, tot_step: 32186, score: 31.0\n",
      "Run: 1407, tot_step: 32211, score: 25.0\n",
      "Run: 1408, tot_step: 32224, score: 13.0\n",
      "Run: 1409, tot_step: 32254, score: 30.0\n",
      "Run: 1410, tot_step: 32272, score: 18.0\n",
      "Run: 1411, tot_step: 32288, score: 16.0\n",
      "Run: 1412, tot_step: 32299, score: 11.0\n",
      "Run: 1413, tot_step: 32313, score: 14.0\n",
      "Run: 1414, tot_step: 32343, score: 30.0\n",
      "Run: 1415, tot_step: 32358, score: 15.0\n",
      "Run: 1416, tot_step: 32390, score: 32.0\n",
      "Run: 1417, tot_step: 32402, score: 12.0\n",
      "Run: 1418, tot_step: 32414, score: 12.0\n",
      "Run: 1419, tot_step: 32438, score: 24.0\n",
      "Run: 1420, tot_step: 32455, score: 17.0\n",
      "Run: 1421, tot_step: 32471, score: 16.0\n",
      "Run: 1422, tot_step: 32486, score: 15.0\n",
      "Run: 1423, tot_step: 32534, score: 48.0\n",
      "Run: 1424, tot_step: 32550, score: 16.0\n",
      "Run: 1425, tot_step: 32574, score: 24.0\n",
      "Run: 1426, tot_step: 32613, score: 39.0\n",
      "Run: 1427, tot_step: 32635, score: 22.0\n",
      "Run: 1428, tot_step: 32659, score: 24.0\n",
      "Run: 1429, tot_step: 32692, score: 33.0\n",
      "Run: 1430, tot_step: 32706, score: 14.0\n",
      "Run: 1431, tot_step: 32714, score: 8.0\n",
      "Run: 1432, tot_step: 32738, score: 24.0\n",
      "Run: 1433, tot_step: 32756, score: 18.0\n",
      "Run: 1434, tot_step: 32781, score: 25.0\n",
      "Run: 1435, tot_step: 32810, score: 29.0\n",
      "Run: 1436, tot_step: 32840, score: 30.0\n",
      "Run: 1437, tot_step: 32872, score: 32.0\n",
      "Run: 1438, tot_step: 32889, score: 17.0\n",
      "Run: 1439, tot_step: 32902, score: 13.0\n",
      "Run: 1440, tot_step: 32915, score: 13.0\n",
      "Run: 1441, tot_step: 32934, score: 19.0\n",
      "Run: 1442, tot_step: 32957, score: 23.0\n",
      "Run: 1443, tot_step: 32980, score: 23.0\n",
      "Run: 1444, tot_step: 33012, score: 32.0\n",
      "Run: 1445, tot_step: 33024, score: 12.0\n",
      "Run: 1446, tot_step: 33063, score: 39.0\n",
      "Run: 1447, tot_step: 33081, score: 18.0\n",
      "Run: 1448, tot_step: 33093, score: 12.0\n",
      "Run: 1449, tot_step: 33122, score: 29.0\n",
      "Run: 1450, tot_step: 33134, score: 12.0\n",
      "Run: 1451, tot_step: 33153, score: 19.0\n",
      "Run: 1452, tot_step: 33180, score: 27.0\n",
      "Run: 1453, tot_step: 33197, score: 17.0\n",
      "Run: 1454, tot_step: 33213, score: 16.0\n",
      "Run: 1455, tot_step: 33230, score: 17.0\n",
      "Run: 1456, tot_step: 33257, score: 27.0\n",
      "Run: 1457, tot_step: 33266, score: 9.0\n",
      "Run: 1458, tot_step: 33281, score: 15.0\n",
      "Run: 1459, tot_step: 33309, score: 28.0\n",
      "Run: 1460, tot_step: 33325, score: 16.0\n",
      "Run: 1461, tot_step: 33364, score: 39.0\n",
      "Run: 1462, tot_step: 33381, score: 17.0\n",
      "Run: 1463, tot_step: 33393, score: 12.0\n",
      "Run: 1464, tot_step: 33407, score: 14.0\n",
      "Run: 1465, tot_step: 33421, score: 14.0\n",
      "Run: 1466, tot_step: 33444, score: 23.0\n",
      "Run: 1467, tot_step: 33454, score: 10.0\n",
      "Run: 1468, tot_step: 33465, score: 11.0\n",
      "Run: 1469, tot_step: 33482, score: 17.0\n",
      "Run: 1470, tot_step: 33502, score: 20.0\n",
      "Run: 1471, tot_step: 33517, score: 15.0\n",
      "Run: 1472, tot_step: 33535, score: 18.0\n",
      "Run: 1473, tot_step: 33553, score: 18.0\n",
      "Run: 1474, tot_step: 33567, score: 14.0\n",
      "Run: 1475, tot_step: 33591, score: 24.0\n",
      "Run: 1476, tot_step: 33627, score: 36.0\n",
      "Run: 1477, tot_step: 33650, score: 23.0\n",
      "Run: 1478, tot_step: 33675, score: 25.0\n",
      "Run: 1479, tot_step: 33700, score: 25.0\n",
      "Run: 1480, tot_step: 33718, score: 18.0\n",
      "Run: 1481, tot_step: 33734, score: 16.0\n",
      "Run: 1482, tot_step: 33743, score: 9.0\n",
      "Run: 1483, tot_step: 33766, score: 23.0\n",
      "Run: 1484, tot_step: 33782, score: 16.0\n",
      "Run: 1485, tot_step: 33798, score: 16.0\n",
      "Run: 1486, tot_step: 33814, score: 16.0\n",
      "Run: 1487, tot_step: 33826, score: 12.0\n",
      "Run: 1488, tot_step: 33842, score: 16.0\n",
      "Run: 1489, tot_step: 33866, score: 24.0\n",
      "Run: 1490, tot_step: 33922, score: 56.0\n",
      "Run: 1491, tot_step: 33936, score: 14.0\n",
      "Run: 1492, tot_step: 33950, score: 14.0\n",
      "Run: 1493, tot_step: 33974, score: 24.0\n",
      "Run: 1494, tot_step: 33993, score: 19.0\n",
      "Run: 1495, tot_step: 34013, score: 20.0\n",
      "Run: 1496, tot_step: 34047, score: 34.0\n",
      "Run: 1497, tot_step: 34058, score: 11.0\n",
      "Run: 1498, tot_step: 34080, score: 22.0\n",
      "Run: 1499, tot_step: 34109, score: 29.0\n",
      "Run: 1500, tot_step: 34134, score: 25.0\n",
      "Run: 1501, tot_step: 34153, score: 19.0\n",
      "Run: 1502, tot_step: 34167, score: 14.0\n",
      "Run: 1503, tot_step: 34196, score: 29.0\n",
      "Run: 1504, tot_step: 34217, score: 21.0\n",
      "Run: 1505, tot_step: 34238, score: 21.0\n",
      "Run: 1506, tot_step: 34249, score: 11.0\n",
      "Run: 1507, tot_step: 34266, score: 17.0\n",
      "Run: 1508, tot_step: 34289, score: 23.0\n",
      "Run: 1509, tot_step: 34302, score: 13.0\n",
      "Run: 1510, tot_step: 34317, score: 15.0\n",
      "Run: 1511, tot_step: 34335, score: 18.0\n",
      "Run: 1512, tot_step: 34351, score: 16.0\n",
      "Run: 1513, tot_step: 34371, score: 20.0\n",
      "Run: 1514, tot_step: 34385, score: 14.0\n",
      "Run: 1515, tot_step: 34404, score: 19.0\n",
      "Run: 1516, tot_step: 34414, score: 10.0\n",
      "Run: 1517, tot_step: 34438, score: 24.0\n",
      "Run: 1518, tot_step: 34476, score: 38.0\n",
      "Run: 1519, tot_step: 34510, score: 34.0\n",
      "Run: 1520, tot_step: 34535, score: 25.0\n",
      "Run: 1521, tot_step: 34550, score: 15.0\n",
      "Run: 1522, tot_step: 34566, score: 16.0\n",
      "Run: 1523, tot_step: 34612, score: 46.0\n",
      "Run: 1524, tot_step: 34624, score: 12.0\n",
      "Run: 1525, tot_step: 34657, score: 33.0\n",
      "Run: 1526, tot_step: 34672, score: 15.0\n",
      "Run: 1527, tot_step: 34698, score: 26.0\n",
      "Run: 1528, tot_step: 34709, score: 11.0\n",
      "Run: 1529, tot_step: 34728, score: 19.0\n",
      "Run: 1530, tot_step: 34764, score: 36.0\n",
      "Run: 1531, tot_step: 34777, score: 13.0\n",
      "Run: 1532, tot_step: 34808, score: 31.0\n",
      "Run: 1533, tot_step: 34840, score: 32.0\n",
      "Run: 1534, tot_step: 34885, score: 45.0\n",
      "Run: 1535, tot_step: 34909, score: 24.0\n",
      "Run: 1536, tot_step: 34931, score: 22.0\n",
      "Run: 1537, tot_step: 34956, score: 25.0\n",
      "Run: 1538, tot_step: 34976, score: 20.0\n",
      "Run: 1539, tot_step: 35006, score: 30.0\n",
      "Run: 1540, tot_step: 35025, score: 19.0\n",
      "Run: 1541, tot_step: 35035, score: 10.0\n",
      "Run: 1542, tot_step: 35075, score: 40.0\n",
      "Run: 1543, tot_step: 35148, score: 73.0\n",
      "Run: 1544, tot_step: 35161, score: 13.0\n",
      "Run: 1545, tot_step: 35182, score: 21.0\n",
      "Run: 1546, tot_step: 35195, score: 13.0\n",
      "Run: 1547, tot_step: 35217, score: 22.0\n",
      "Run: 1548, tot_step: 35240, score: 23.0\n",
      "Run: 1549, tot_step: 35258, score: 18.0\n",
      "Run: 1550, tot_step: 35274, score: 16.0\n",
      "Run: 1551, tot_step: 35287, score: 13.0\n",
      "Run: 1552, tot_step: 35315, score: 28.0\n",
      "Run: 1553, tot_step: 35328, score: 13.0\n",
      "Run: 1554, tot_step: 35348, score: 20.0\n",
      "Run: 1555, tot_step: 35357, score: 9.0\n",
      "Run: 1556, tot_step: 35374, score: 17.0\n",
      "Run: 1557, tot_step: 35392, score: 18.0\n",
      "Run: 1558, tot_step: 35419, score: 27.0\n",
      "Run: 1559, tot_step: 35430, score: 11.0\n",
      "Run: 1560, tot_step: 35442, score: 12.0\n",
      "Run: 1561, tot_step: 35485, score: 43.0\n",
      "Run: 1562, tot_step: 35505, score: 20.0\n",
      "Run: 1563, tot_step: 35516, score: 11.0\n",
      "Run: 1564, tot_step: 35529, score: 13.0\n",
      "Run: 1565, tot_step: 35560, score: 31.0\n",
      "Run: 1566, tot_step: 35611, score: 51.0\n",
      "Run: 1567, tot_step: 35628, score: 17.0\n",
      "Run: 1568, tot_step: 35644, score: 16.0\n",
      "Run: 1569, tot_step: 35663, score: 19.0\n",
      "Run: 1570, tot_step: 35685, score: 22.0\n",
      "Run: 1571, tot_step: 35700, score: 15.0\n",
      "Run: 1572, tot_step: 35710, score: 10.0\n",
      "Run: 1573, tot_step: 35728, score: 18.0\n",
      "Run: 1574, tot_step: 35756, score: 28.0\n",
      "Run: 1575, tot_step: 35785, score: 29.0\n",
      "Run: 1576, tot_step: 35801, score: 16.0\n",
      "Run: 1577, tot_step: 35817, score: 16.0\n",
      "Run: 1578, tot_step: 35835, score: 18.0\n",
      "Run: 1579, tot_step: 35870, score: 35.0\n",
      "Run: 1580, tot_step: 35889, score: 19.0\n",
      "Run: 1581, tot_step: 35912, score: 23.0\n",
      "Run: 1582, tot_step: 35925, score: 13.0\n",
      "Run: 1583, tot_step: 35939, score: 14.0\n",
      "Run: 1584, tot_step: 35952, score: 13.0\n",
      "Run: 1585, tot_step: 35984, score: 32.0\n",
      "Run: 1586, tot_step: 36001, score: 17.0\n",
      "Run: 1587, tot_step: 36020, score: 19.0\n",
      "Run: 1588, tot_step: 36032, score: 12.0\n",
      "Run: 1589, tot_step: 36045, score: 13.0\n",
      "Run: 1590, tot_step: 36060, score: 15.0\n",
      "Run: 1591, tot_step: 36076, score: 16.0\n",
      "Run: 1592, tot_step: 36091, score: 15.0\n",
      "Run: 1593, tot_step: 36110, score: 19.0\n",
      "Run: 1594, tot_step: 36149, score: 39.0\n",
      "Run: 1595, tot_step: 36159, score: 10.0\n",
      "Run: 1596, tot_step: 36180, score: 21.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1597, tot_step: 36200, score: 20.0\n",
      "Run: 1598, tot_step: 36216, score: 16.0\n",
      "Run: 1599, tot_step: 36240, score: 24.0\n",
      "Run: 1600, tot_step: 36278, score: 38.0\n",
      "Run: 1601, tot_step: 36295, score: 17.0\n",
      "Run: 1602, tot_step: 36311, score: 16.0\n",
      "Run: 1603, tot_step: 36336, score: 25.0\n",
      "Run: 1604, tot_step: 36347, score: 11.0\n",
      "Run: 1605, tot_step: 36358, score: 11.0\n",
      "Run: 1606, tot_step: 36390, score: 32.0\n",
      "Run: 1607, tot_step: 36408, score: 18.0\n",
      "Run: 1608, tot_step: 36423, score: 15.0\n",
      "Run: 1609, tot_step: 36442, score: 19.0\n",
      "Run: 1610, tot_step: 36455, score: 13.0\n",
      "Run: 1611, tot_step: 36467, score: 12.0\n",
      "Run: 1612, tot_step: 36482, score: 15.0\n",
      "Run: 1613, tot_step: 36492, score: 10.0\n",
      "Run: 1614, tot_step: 36531, score: 39.0\n",
      "Run: 1615, tot_step: 36575, score: 44.0\n",
      "Run: 1616, tot_step: 36602, score: 27.0\n",
      "Run: 1617, tot_step: 36617, score: 15.0\n",
      "Run: 1618, tot_step: 36631, score: 14.0\n",
      "Run: 1619, tot_step: 36670, score: 39.0\n",
      "Run: 1620, tot_step: 36692, score: 22.0\n",
      "Run: 1621, tot_step: 36707, score: 15.0\n",
      "Run: 1622, tot_step: 36719, score: 12.0\n",
      "Run: 1623, tot_step: 36735, score: 16.0\n",
      "Run: 1624, tot_step: 36747, score: 12.0\n",
      "Run: 1625, tot_step: 36773, score: 26.0\n",
      "Run: 1626, tot_step: 36792, score: 19.0\n",
      "Run: 1627, tot_step: 36808, score: 16.0\n",
      "Run: 1628, tot_step: 36826, score: 18.0\n",
      "Run: 1629, tot_step: 36838, score: 12.0\n",
      "Run: 1630, tot_step: 36848, score: 10.0\n",
      "Run: 1631, tot_step: 36868, score: 20.0\n",
      "Run: 1632, tot_step: 36885, score: 17.0\n",
      "Run: 1633, tot_step: 36913, score: 28.0\n",
      "Run: 1634, tot_step: 36929, score: 16.0\n",
      "Run: 1635, tot_step: 36942, score: 13.0\n",
      "Run: 1636, tot_step: 36963, score: 21.0\n",
      "Run: 1637, tot_step: 37008, score: 45.0\n",
      "Run: 1638, tot_step: 37029, score: 21.0\n",
      "Run: 1639, tot_step: 37055, score: 26.0\n",
      "Run: 1640, tot_step: 37088, score: 33.0\n",
      "Run: 1641, tot_step: 37120, score: 32.0\n",
      "Run: 1642, tot_step: 37157, score: 37.0\n",
      "Run: 1643, tot_step: 37167, score: 10.0\n",
      "Run: 1644, tot_step: 37193, score: 26.0\n",
      "Run: 1645, tot_step: 37207, score: 14.0\n",
      "Run: 1646, tot_step: 37219, score: 12.0\n",
      "Run: 1647, tot_step: 37234, score: 15.0\n",
      "Run: 1648, tot_step: 37250, score: 16.0\n",
      "Run: 1649, tot_step: 37262, score: 12.0\n",
      "Run: 1650, tot_step: 37275, score: 13.0\n",
      "Run: 1651, tot_step: 37311, score: 36.0\n",
      "Run: 1652, tot_step: 37324, score: 13.0\n",
      "Run: 1653, tot_step: 37349, score: 25.0\n",
      "Run: 1654, tot_step: 37362, score: 13.0\n",
      "Run: 1655, tot_step: 37386, score: 24.0\n",
      "Run: 1656, tot_step: 37430, score: 44.0\n",
      "Run: 1657, tot_step: 37473, score: 43.0\n",
      "Run: 1658, tot_step: 37494, score: 21.0\n",
      "Run: 1659, tot_step: 37513, score: 19.0\n",
      "Run: 1660, tot_step: 37552, score: 39.0\n",
      "Run: 1661, tot_step: 37565, score: 13.0\n",
      "Run: 1662, tot_step: 37594, score: 29.0\n",
      "Run: 1663, tot_step: 37613, score: 19.0\n",
      "Run: 1664, tot_step: 37629, score: 16.0\n",
      "Run: 1665, tot_step: 37698, score: 69.0\n",
      "Run: 1666, tot_step: 37715, score: 17.0\n",
      "Run: 1667, tot_step: 37731, score: 16.0\n",
      "Run: 1668, tot_step: 37743, score: 12.0\n",
      "Run: 1669, tot_step: 37764, score: 21.0\n",
      "Run: 1670, tot_step: 37778, score: 14.0\n",
      "Run: 1671, tot_step: 37797, score: 19.0\n",
      "Run: 1672, tot_step: 37823, score: 26.0\n",
      "Run: 1673, tot_step: 37855, score: 32.0\n",
      "Run: 1674, tot_step: 37872, score: 17.0\n",
      "Run: 1675, tot_step: 37883, score: 11.0\n",
      "Run: 1676, tot_step: 37897, score: 14.0\n",
      "Run: 1677, tot_step: 37911, score: 14.0\n",
      "Run: 1678, tot_step: 37936, score: 25.0\n",
      "Run: 1679, tot_step: 37958, score: 22.0\n",
      "Run: 1680, tot_step: 38019, score: 61.0\n",
      "Run: 1681, tot_step: 38044, score: 25.0\n",
      "Run: 1682, tot_step: 38064, score: 20.0\n",
      "Run: 1683, tot_step: 38080, score: 16.0\n",
      "Run: 1684, tot_step: 38111, score: 31.0\n",
      "Run: 1685, tot_step: 38135, score: 24.0\n",
      "Run: 1686, tot_step: 38145, score: 10.0\n",
      "Run: 1687, tot_step: 38168, score: 23.0\n",
      "Run: 1688, tot_step: 38181, score: 13.0\n",
      "Run: 1689, tot_step: 38200, score: 19.0\n",
      "Run: 1690, tot_step: 38217, score: 17.0\n",
      "Run: 1691, tot_step: 38255, score: 38.0\n",
      "Run: 1692, tot_step: 38283, score: 28.0\n",
      "Run: 1693, tot_step: 38316, score: 33.0\n",
      "Run: 1694, tot_step: 38342, score: 26.0\n",
      "Run: 1695, tot_step: 38353, score: 11.0\n",
      "Run: 1696, tot_step: 38380, score: 27.0\n",
      "Run: 1697, tot_step: 38403, score: 23.0\n",
      "Run: 1698, tot_step: 38452, score: 49.0\n",
      "Run: 1699, tot_step: 38471, score: 19.0\n",
      "Run: 1700, tot_step: 38485, score: 14.0\n",
      "Run: 1701, tot_step: 38508, score: 23.0\n",
      "Run: 1702, tot_step: 38523, score: 15.0\n",
      "Run: 1703, tot_step: 38536, score: 13.0\n",
      "Run: 1704, tot_step: 38549, score: 13.0\n",
      "Run: 1705, tot_step: 38569, score: 20.0\n",
      "Run: 1706, tot_step: 38600, score: 31.0\n",
      "Run: 1707, tot_step: 38611, score: 11.0\n",
      "Run: 1708, tot_step: 38629, score: 18.0\n",
      "Run: 1709, tot_step: 38653, score: 24.0\n",
      "Run: 1710, tot_step: 38669, score: 16.0\n",
      "Run: 1711, tot_step: 38685, score: 16.0\n",
      "Run: 1712, tot_step: 38704, score: 19.0\n",
      "Run: 1713, tot_step: 38719, score: 15.0\n",
      "Run: 1714, tot_step: 38738, score: 19.0\n",
      "Run: 1715, tot_step: 38760, score: 22.0\n",
      "Run: 1716, tot_step: 38775, score: 15.0\n",
      "Run: 1717, tot_step: 38796, score: 21.0\n",
      "Run: 1718, tot_step: 38849, score: 53.0\n",
      "Run: 1719, tot_step: 38875, score: 26.0\n",
      "Run: 1720, tot_step: 38909, score: 34.0\n",
      "Run: 1721, tot_step: 38934, score: 25.0\n",
      "Run: 1722, tot_step: 38950, score: 16.0\n",
      "Run: 1723, tot_step: 38987, score: 37.0\n",
      "Run: 1724, tot_step: 39008, score: 21.0\n",
      "Run: 1725, tot_step: 39050, score: 42.0\n",
      "Run: 1726, tot_step: 39091, score: 41.0\n",
      "Run: 1727, tot_step: 39103, score: 12.0\n",
      "Run: 1728, tot_step: 39122, score: 19.0\n",
      "Run: 1729, tot_step: 39139, score: 17.0\n",
      "Run: 1730, tot_step: 39154, score: 15.0\n",
      "Run: 1731, tot_step: 39197, score: 43.0\n",
      "Run: 1732, tot_step: 39240, score: 43.0\n",
      "Run: 1733, tot_step: 39257, score: 17.0\n",
      "Run: 1734, tot_step: 39269, score: 12.0\n",
      "Run: 1735, tot_step: 39295, score: 26.0\n",
      "Run: 1736, tot_step: 39323, score: 28.0\n",
      "Run: 1737, tot_step: 39341, score: 18.0\n",
      "Run: 1738, tot_step: 39355, score: 14.0\n",
      "Run: 1739, tot_step: 39365, score: 10.0\n",
      "Run: 1740, tot_step: 39379, score: 14.0\n",
      "Run: 1741, tot_step: 39395, score: 16.0\n",
      "Run: 1742, tot_step: 39409, score: 14.0\n",
      "Run: 1743, tot_step: 39433, score: 24.0\n",
      "Run: 1744, tot_step: 39473, score: 40.0\n",
      "Run: 1745, tot_step: 39482, score: 9.0\n",
      "Run: 1746, tot_step: 39524, score: 42.0\n",
      "Run: 1747, tot_step: 39539, score: 15.0\n",
      "Run: 1748, tot_step: 39556, score: 17.0\n",
      "Run: 1749, tot_step: 39610, score: 54.0\n",
      "Run: 1750, tot_step: 39628, score: 18.0\n",
      "Run: 1751, tot_step: 39649, score: 21.0\n",
      "Run: 1752, tot_step: 39695, score: 46.0\n",
      "Run: 1753, tot_step: 39725, score: 30.0\n",
      "Run: 1754, tot_step: 39761, score: 36.0\n",
      "Run: 1755, tot_step: 39773, score: 12.0\n",
      "Run: 1756, tot_step: 39789, score: 16.0\n",
      "Run: 1757, tot_step: 39819, score: 30.0\n",
      "Run: 1758, tot_step: 39832, score: 13.0\n",
      "Run: 1759, tot_step: 39845, score: 13.0\n",
      "Run: 1760, tot_step: 39873, score: 28.0\n",
      "Run: 1761, tot_step: 39887, score: 14.0\n",
      "Run: 1762, tot_step: 39901, score: 14.0\n",
      "Run: 1763, tot_step: 39925, score: 24.0\n",
      "Run: 1764, tot_step: 39938, score: 13.0\n",
      "Run: 1765, tot_step: 39959, score: 21.0\n",
      "Run: 1766, tot_step: 40000, score: 41.0\n",
      "Run: 1767, tot_step: 40063, score: 63.0\n",
      "Run: 1768, tot_step: 40077, score: 14.0\n",
      "Run: 1769, tot_step: 40097, score: 20.0\n",
      "Run: 1770, tot_step: 40109, score: 12.0\n",
      "Run: 1771, tot_step: 40123, score: 14.0\n",
      "Run: 1772, tot_step: 40141, score: 18.0\n",
      "Run: 1773, tot_step: 40155, score: 14.0\n",
      "Run: 1774, tot_step: 40184, score: 29.0\n",
      "Run: 1775, tot_step: 40203, score: 19.0\n",
      "Run: 1776, tot_step: 40215, score: 12.0\n",
      "Run: 1777, tot_step: 40234, score: 19.0\n",
      "Run: 1778, tot_step: 40251, score: 17.0\n",
      "Run: 1779, tot_step: 40269, score: 18.0\n",
      "Run: 1780, tot_step: 40280, score: 11.0\n",
      "Run: 1781, tot_step: 40290, score: 10.0\n",
      "Run: 1782, tot_step: 40307, score: 17.0\n",
      "Run: 1783, tot_step: 40342, score: 35.0\n",
      "Run: 1784, tot_step: 40358, score: 16.0\n",
      "Run: 1785, tot_step: 40379, score: 21.0\n",
      "Run: 1786, tot_step: 40404, score: 25.0\n",
      "Run: 1787, tot_step: 40423, score: 19.0\n",
      "Run: 1788, tot_step: 40438, score: 15.0\n",
      "Run: 1789, tot_step: 40486, score: 48.0\n",
      "Run: 1790, tot_step: 40508, score: 22.0\n",
      "Run: 1791, tot_step: 40540, score: 32.0\n",
      "Run: 1792, tot_step: 40554, score: 14.0\n",
      "Run: 1793, tot_step: 40574, score: 20.0\n",
      "Run: 1794, tot_step: 40585, score: 11.0\n",
      "Run: 1795, tot_step: 40619, score: 34.0\n",
      "Run: 1796, tot_step: 40660, score: 41.0\n",
      "Run: 1797, tot_step: 40674, score: 14.0\n",
      "Run: 1798, tot_step: 40688, score: 14.0\n",
      "Run: 1799, tot_step: 40699, score: 11.0\n",
      "Run: 1800, tot_step: 40728, score: 29.0\n",
      "Run: 1801, tot_step: 40755, score: 27.0\n",
      "Run: 1802, tot_step: 40784, score: 29.0\n",
      "Run: 1803, tot_step: 40800, score: 16.0\n",
      "Run: 1804, tot_step: 40814, score: 14.0\n",
      "Run: 1805, tot_step: 40834, score: 20.0\n",
      "Run: 1806, tot_step: 40847, score: 13.0\n",
      "Run: 1807, tot_step: 40886, score: 39.0\n",
      "Run: 1808, tot_step: 40896, score: 10.0\n",
      "Run: 1809, tot_step: 40911, score: 15.0\n",
      "Run: 1810, tot_step: 40922, score: 11.0\n",
      "Run: 1811, tot_step: 40937, score: 15.0\n",
      "Run: 1812, tot_step: 41019, score: 82.0\n",
      "Run: 1813, tot_step: 41035, score: 16.0\n",
      "Run: 1814, tot_step: 41050, score: 15.0\n",
      "Run: 1815, tot_step: 41063, score: 13.0\n",
      "Run: 1816, tot_step: 41074, score: 11.0\n",
      "Run: 1817, tot_step: 41096, score: 22.0\n",
      "Run: 1818, tot_step: 41115, score: 19.0\n",
      "Run: 1819, tot_step: 41141, score: 26.0\n",
      "Run: 1820, tot_step: 41165, score: 24.0\n",
      "Run: 1821, tot_step: 41179, score: 14.0\n",
      "Run: 1822, tot_step: 41193, score: 14.0\n",
      "Run: 1823, tot_step: 41219, score: 26.0\n",
      "Run: 1824, tot_step: 41236, score: 17.0\n",
      "Run: 1825, tot_step: 41250, score: 14.0\n",
      "Run: 1826, tot_step: 41265, score: 15.0\n",
      "Run: 1827, tot_step: 41279, score: 14.0\n",
      "Run: 1828, tot_step: 41293, score: 14.0\n",
      "Run: 1829, tot_step: 41323, score: 30.0\n",
      "Run: 1830, tot_step: 41346, score: 23.0\n",
      "Run: 1831, tot_step: 41361, score: 15.0\n",
      "Run: 1832, tot_step: 41371, score: 10.0\n",
      "Run: 1833, tot_step: 41387, score: 16.0\n",
      "Run: 1834, tot_step: 41420, score: 33.0\n",
      "Run: 1835, tot_step: 41436, score: 16.0\n",
      "Run: 1836, tot_step: 41453, score: 17.0\n",
      "Run: 1837, tot_step: 41479, score: 26.0\n",
      "Run: 1838, tot_step: 41490, score: 11.0\n",
      "Run: 1839, tot_step: 41504, score: 14.0\n",
      "Run: 1840, tot_step: 41519, score: 15.0\n",
      "Run: 1841, tot_step: 41535, score: 16.0\n",
      "Run: 1842, tot_step: 41562, score: 27.0\n",
      "Run: 1843, tot_step: 41588, score: 26.0\n",
      "Run: 1844, tot_step: 41605, score: 17.0\n",
      "Run: 1845, tot_step: 41631, score: 26.0\n",
      "Run: 1846, tot_step: 41647, score: 16.0\n",
      "Run: 1847, tot_step: 41665, score: 18.0\n",
      "Run: 1848, tot_step: 41683, score: 18.0\n",
      "Run: 1849, tot_step: 41698, score: 15.0\n",
      "Run: 1850, tot_step: 41713, score: 15.0\n",
      "Run: 1851, tot_step: 41736, score: 23.0\n",
      "Run: 1852, tot_step: 41754, score: 18.0\n",
      "Run: 1853, tot_step: 41774, score: 20.0\n",
      "Run: 1854, tot_step: 41793, score: 19.0\n",
      "Run: 1855, tot_step: 41813, score: 20.0\n",
      "Run: 1856, tot_step: 41844, score: 31.0\n",
      "Run: 1857, tot_step: 41869, score: 25.0\n",
      "Run: 1858, tot_step: 41878, score: 9.0\n",
      "Run: 1859, tot_step: 41908, score: 30.0\n",
      "Run: 1860, tot_step: 41966, score: 58.0\n",
      "Run: 1861, tot_step: 42041, score: 75.0\n",
      "Run: 1862, tot_step: 42061, score: 20.0\n",
      "Run: 1863, tot_step: 42116, score: 55.0\n",
      "Run: 1864, tot_step: 42128, score: 12.0\n",
      "Run: 1865, tot_step: 42149, score: 21.0\n",
      "Run: 1866, tot_step: 42159, score: 10.0\n",
      "Run: 1867, tot_step: 42178, score: 19.0\n",
      "Run: 1868, tot_step: 42199, score: 21.0\n",
      "Run: 1869, tot_step: 42214, score: 15.0\n",
      "Run: 1870, tot_step: 42227, score: 13.0\n",
      "Run: 1871, tot_step: 42244, score: 17.0\n",
      "Run: 1872, tot_step: 42258, score: 14.0\n",
      "Run: 1873, tot_step: 42279, score: 21.0\n",
      "Run: 1874, tot_step: 42306, score: 27.0\n",
      "Run: 1875, tot_step: 42328, score: 22.0\n",
      "Run: 1876, tot_step: 42366, score: 38.0\n",
      "Run: 1877, tot_step: 42415, score: 49.0\n",
      "Run: 1878, tot_step: 42425, score: 10.0\n",
      "Run: 1879, tot_step: 42435, score: 10.0\n",
      "Run: 1880, tot_step: 42452, score: 17.0\n",
      "Run: 1881, tot_step: 42468, score: 16.0\n",
      "Run: 1882, tot_step: 42483, score: 15.0\n",
      "Run: 1883, tot_step: 42503, score: 20.0\n",
      "Run: 1884, tot_step: 42525, score: 22.0\n",
      "Run: 1885, tot_step: 42535, score: 10.0\n",
      "Run: 1886, tot_step: 42595, score: 60.0\n",
      "Run: 1887, tot_step: 42615, score: 20.0\n",
      "Run: 1888, tot_step: 42628, score: 13.0\n",
      "Run: 1889, tot_step: 42646, score: 18.0\n",
      "Run: 1890, tot_step: 42659, score: 13.0\n",
      "Run: 1891, tot_step: 42676, score: 17.0\n",
      "Run: 1892, tot_step: 42692, score: 16.0\n",
      "Run: 1893, tot_step: 42712, score: 20.0\n",
      "Run: 1894, tot_step: 42726, score: 14.0\n",
      "Run: 1895, tot_step: 42746, score: 20.0\n",
      "Run: 1896, tot_step: 42770, score: 24.0\n",
      "Run: 1897, tot_step: 42790, score: 20.0\n",
      "Run: 1898, tot_step: 42805, score: 15.0\n",
      "Run: 1899, tot_step: 42822, score: 17.0\n",
      "Run: 1900, tot_step: 42847, score: 25.0\n",
      "Run: 1901, tot_step: 42859, score: 12.0\n",
      "Run: 1902, tot_step: 42873, score: 14.0\n",
      "Run: 1903, tot_step: 42890, score: 17.0\n",
      "Run: 1904, tot_step: 42923, score: 33.0\n",
      "Run: 1905, tot_step: 42941, score: 18.0\n",
      "Run: 1906, tot_step: 42969, score: 28.0\n",
      "Run: 1907, tot_step: 42991, score: 22.0\n",
      "Run: 1908, tot_step: 43007, score: 16.0\n",
      "Run: 1909, tot_step: 43030, score: 23.0\n",
      "Run: 1910, tot_step: 43065, score: 35.0\n",
      "Run: 1911, tot_step: 43079, score: 14.0\n",
      "Run: 1912, tot_step: 43092, score: 13.0\n",
      "Run: 1913, tot_step: 43113, score: 21.0\n",
      "Run: 1914, tot_step: 43143, score: 30.0\n",
      "Run: 1915, tot_step: 43208, score: 65.0\n",
      "Run: 1916, tot_step: 43220, score: 12.0\n",
      "Run: 1917, tot_step: 43246, score: 26.0\n",
      "Run: 1918, tot_step: 43280, score: 34.0\n",
      "Run: 1919, tot_step: 43293, score: 13.0\n",
      "Run: 1920, tot_step: 43303, score: 10.0\n",
      "Run: 1921, tot_step: 43338, score: 35.0\n",
      "Run: 1922, tot_step: 43376, score: 38.0\n",
      "Run: 1923, tot_step: 43386, score: 10.0\n",
      "Run: 1924, tot_step: 43401, score: 15.0\n",
      "Run: 1925, tot_step: 43418, score: 17.0\n",
      "Run: 1926, tot_step: 43437, score: 19.0\n",
      "Run: 1927, tot_step: 43447, score: 10.0\n",
      "Run: 1928, tot_step: 43465, score: 18.0\n",
      "Run: 1929, tot_step: 43476, score: 11.0\n",
      "Run: 1930, tot_step: 43494, score: 18.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1931, tot_step: 43505, score: 11.0\n",
      "Run: 1932, tot_step: 43515, score: 10.0\n",
      "Run: 1933, tot_step: 43546, score: 31.0\n",
      "Run: 1934, tot_step: 43561, score: 15.0\n",
      "Run: 1935, tot_step: 43579, score: 18.0\n",
      "Run: 1936, tot_step: 43604, score: 25.0\n",
      "Run: 1937, tot_step: 43624, score: 20.0\n",
      "Run: 1938, tot_step: 43678, score: 54.0\n",
      "Run: 1939, tot_step: 43700, score: 22.0\n",
      "Run: 1940, tot_step: 43722, score: 22.0\n",
      "Run: 1941, tot_step: 43740, score: 18.0\n",
      "Run: 1942, tot_step: 43754, score: 14.0\n",
      "Run: 1943, tot_step: 43875, score: 121.0\n",
      "Run: 1944, tot_step: 43895, score: 20.0\n",
      "Run: 1945, tot_step: 43915, score: 20.0\n",
      "Run: 1946, tot_step: 43927, score: 12.0\n",
      "Run: 1947, tot_step: 43938, score: 11.0\n",
      "Run: 1948, tot_step: 43950, score: 12.0\n",
      "Run: 1949, tot_step: 43962, score: 12.0\n",
      "Run: 1950, tot_step: 44016, score: 54.0\n",
      "Run: 1951, tot_step: 44054, score: 38.0\n",
      "Run: 1952, tot_step: 44072, score: 18.0\n",
      "Run: 1953, tot_step: 44110, score: 38.0\n",
      "Run: 1954, tot_step: 44131, score: 21.0\n",
      "Run: 1955, tot_step: 44146, score: 15.0\n",
      "Run: 1956, tot_step: 44157, score: 11.0\n",
      "Run: 1957, tot_step: 44169, score: 12.0\n",
      "Run: 1958, tot_step: 44190, score: 21.0\n",
      "Run: 1959, tot_step: 44202, score: 12.0\n",
      "Run: 1960, tot_step: 44211, score: 9.0\n",
      "Run: 1961, tot_step: 44225, score: 14.0\n",
      "Run: 1962, tot_step: 44242, score: 17.0\n",
      "Run: 1963, tot_step: 44266, score: 24.0\n",
      "Run: 1964, tot_step: 44341, score: 75.0\n",
      "Run: 1965, tot_step: 44355, score: 14.0\n",
      "Run: 1966, tot_step: 44365, score: 10.0\n",
      "Run: 1967, tot_step: 44381, score: 16.0\n",
      "Run: 1968, tot_step: 44391, score: 10.0\n",
      "Run: 1969, tot_step: 44408, score: 17.0\n",
      "Run: 1970, tot_step: 44446, score: 38.0\n",
      "Run: 1971, tot_step: 44463, score: 17.0\n",
      "Run: 1972, tot_step: 44486, score: 23.0\n",
      "Run: 1973, tot_step: 44509, score: 23.0\n",
      "Run: 1974, tot_step: 44531, score: 22.0\n",
      "Run: 1975, tot_step: 44541, score: 10.0\n",
      "Run: 1976, tot_step: 44565, score: 24.0\n",
      "Run: 1977, tot_step: 44575, score: 10.0\n",
      "Run: 1978, tot_step: 44592, score: 17.0\n",
      "Run: 1979, tot_step: 44606, score: 14.0\n",
      "Run: 1980, tot_step: 44635, score: 29.0\n",
      "Run: 1981, tot_step: 44650, score: 15.0\n",
      "Run: 1982, tot_step: 44663, score: 13.0\n",
      "Run: 1983, tot_step: 44680, score: 17.0\n",
      "Run: 1984, tot_step: 44713, score: 33.0\n",
      "Run: 1985, tot_step: 44745, score: 32.0\n",
      "Run: 1986, tot_step: 44766, score: 21.0\n",
      "Run: 1987, tot_step: 44781, score: 15.0\n",
      "Run: 1988, tot_step: 44811, score: 30.0\n",
      "Run: 1989, tot_step: 44833, score: 22.0\n",
      "Run: 1990, tot_step: 44859, score: 26.0\n",
      "Run: 1991, tot_step: 44869, score: 10.0\n",
      "Run: 1992, tot_step: 44899, score: 30.0\n",
      "Run: 1993, tot_step: 44927, score: 28.0\n",
      "Run: 1994, tot_step: 44969, score: 42.0\n",
      "Run: 1995, tot_step: 44985, score: 16.0\n",
      "Run: 1996, tot_step: 45013, score: 28.0\n",
      "Run: 1997, tot_step: 45036, score: 23.0\n",
      "Run: 1998, tot_step: 45050, score: 14.0\n",
      "Run: 1999, tot_step: 45076, score: 26.0\n",
      "Run: 2000, tot_step: 45108, score: 32.0\n",
      "Run: 2001, tot_step: 45132, score: 24.0\n",
      "Run: 2002, tot_step: 45145, score: 13.0\n",
      "Run: 2003, tot_step: 45178, score: 33.0\n",
      "Run: 2004, tot_step: 45200, score: 22.0\n",
      "Run: 2005, tot_step: 45211, score: 11.0\n",
      "Run: 2006, tot_step: 45255, score: 44.0\n",
      "Run: 2007, tot_step: 45279, score: 24.0\n",
      "Run: 2008, tot_step: 45308, score: 29.0\n",
      "Run: 2009, tot_step: 45322, score: 14.0\n",
      "Run: 2010, tot_step: 45343, score: 21.0\n",
      "Run: 2011, tot_step: 45362, score: 19.0\n",
      "Run: 2012, tot_step: 45381, score: 19.0\n",
      "Run: 2013, tot_step: 45398, score: 17.0\n",
      "Run: 2014, tot_step: 45418, score: 20.0\n",
      "Run: 2015, tot_step: 45437, score: 19.0\n",
      "Run: 2016, tot_step: 45467, score: 30.0\n",
      "Run: 2017, tot_step: 45478, score: 11.0\n",
      "Run: 2018, tot_step: 45503, score: 25.0\n",
      "Run: 2019, tot_step: 45555, score: 52.0\n",
      "Run: 2020, tot_step: 45597, score: 42.0\n",
      "Run: 2021, tot_step: 45609, score: 12.0\n",
      "Run: 2022, tot_step: 45620, score: 11.0\n",
      "Run: 2023, tot_step: 45654, score: 34.0\n",
      "Run: 2024, tot_step: 45674, score: 20.0\n",
      "Run: 2025, tot_step: 45699, score: 25.0\n",
      "Run: 2026, tot_step: 45709, score: 10.0\n",
      "Run: 2027, tot_step: 45727, score: 18.0\n",
      "Run: 2028, tot_step: 45740, score: 13.0\n",
      "Run: 2029, tot_step: 45759, score: 19.0\n",
      "Run: 2030, tot_step: 45777, score: 18.0\n",
      "Run: 2031, tot_step: 45790, score: 13.0\n",
      "Run: 2032, tot_step: 45813, score: 23.0\n",
      "Run: 2033, tot_step: 45835, score: 22.0\n",
      "Run: 2034, tot_step: 45848, score: 13.0\n",
      "Run: 2035, tot_step: 45859, score: 11.0\n",
      "Run: 2036, tot_step: 45873, score: 14.0\n",
      "Run: 2037, tot_step: 45894, score: 21.0\n",
      "Run: 2038, tot_step: 45938, score: 44.0\n",
      "Run: 2039, tot_step: 45948, score: 10.0\n",
      "Run: 2040, tot_step: 45962, score: 14.0\n",
      "Run: 2041, tot_step: 45974, score: 12.0\n",
      "Run: 2042, tot_step: 45992, score: 18.0\n",
      "Run: 2043, tot_step: 46009, score: 17.0\n",
      "Run: 2044, tot_step: 46022, score: 13.0\n",
      "Run: 2045, tot_step: 46033, score: 11.0\n",
      "Run: 2046, tot_step: 46065, score: 32.0\n",
      "Run: 2047, tot_step: 46101, score: 36.0\n",
      "Run: 2048, tot_step: 46128, score: 27.0\n",
      "Run: 2049, tot_step: 46137, score: 9.0\n",
      "Run: 2050, tot_step: 46151, score: 14.0\n",
      "Run: 2051, tot_step: 46161, score: 10.0\n",
      "Run: 2052, tot_step: 46180, score: 19.0\n",
      "Run: 2053, tot_step: 46206, score: 26.0\n",
      "Run: 2054, tot_step: 46219, score: 13.0\n",
      "Run: 2055, tot_step: 46257, score: 38.0\n",
      "Run: 2056, tot_step: 46272, score: 15.0\n",
      "Run: 2057, tot_step: 46289, score: 17.0\n",
      "Run: 2058, tot_step: 46309, score: 20.0\n",
      "Run: 2059, tot_step: 46329, score: 20.0\n",
      "Run: 2060, tot_step: 46346, score: 17.0\n",
      "Run: 2061, tot_step: 46361, score: 15.0\n",
      "Run: 2062, tot_step: 46371, score: 10.0\n",
      "Run: 2063, tot_step: 46383, score: 12.0\n",
      "Run: 2064, tot_step: 46405, score: 22.0\n",
      "Run: 2065, tot_step: 46418, score: 13.0\n",
      "Run: 2066, tot_step: 46439, score: 21.0\n",
      "Run: 2067, tot_step: 46459, score: 20.0\n",
      "Run: 2068, tot_step: 46477, score: 18.0\n",
      "Run: 2069, tot_step: 46546, score: 69.0\n",
      "Run: 2070, tot_step: 46563, score: 17.0\n",
      "Run: 2071, tot_step: 46583, score: 20.0\n",
      "Run: 2072, tot_step: 46599, score: 16.0\n",
      "Run: 2073, tot_step: 46614, score: 15.0\n",
      "Run: 2074, tot_step: 46651, score: 37.0\n",
      "Run: 2075, tot_step: 46674, score: 23.0\n",
      "Run: 2076, tot_step: 46698, score: 24.0\n",
      "Run: 2077, tot_step: 46725, score: 27.0\n",
      "Run: 2078, tot_step: 46749, score: 24.0\n",
      "Run: 2079, tot_step: 46776, score: 27.0\n",
      "Run: 2080, tot_step: 46817, score: 41.0\n",
      "Run: 2081, tot_step: 46836, score: 19.0\n",
      "Run: 2082, tot_step: 46863, score: 27.0\n",
      "Run: 2083, tot_step: 46879, score: 16.0\n",
      "Run: 2084, tot_step: 46903, score: 24.0\n",
      "Run: 2085, tot_step: 46927, score: 24.0\n",
      "Run: 2086, tot_step: 46947, score: 20.0\n",
      "Run: 2087, tot_step: 46961, score: 14.0\n",
      "Run: 2088, tot_step: 46983, score: 22.0\n",
      "Run: 2089, tot_step: 47007, score: 24.0\n",
      "Run: 2090, tot_step: 47038, score: 31.0\n",
      "Run: 2091, tot_step: 47075, score: 37.0\n",
      "Run: 2092, tot_step: 47104, score: 29.0\n",
      "Run: 2093, tot_step: 47113, score: 9.0\n",
      "Run: 2094, tot_step: 47182, score: 69.0\n",
      "Run: 2095, tot_step: 47197, score: 15.0\n",
      "Run: 2096, tot_step: 47222, score: 25.0\n",
      "Run: 2097, tot_step: 47234, score: 12.0\n",
      "Run: 2098, tot_step: 47247, score: 13.0\n",
      "Run: 2099, tot_step: 47260, score: 13.0\n",
      "Run: 2100, tot_step: 47275, score: 15.0\n",
      "Run: 2101, tot_step: 47291, score: 16.0\n",
      "Run: 2102, tot_step: 47307, score: 16.0\n",
      "Run: 2103, tot_step: 47328, score: 21.0\n",
      "Run: 2104, tot_step: 47347, score: 19.0\n",
      "Run: 2105, tot_step: 47358, score: 11.0\n",
      "Run: 2106, tot_step: 47390, score: 32.0\n",
      "Run: 2107, tot_step: 47407, score: 17.0\n",
      "Run: 2108, tot_step: 47434, score: 27.0\n",
      "Run: 2109, tot_step: 47461, score: 27.0\n",
      "Run: 2110, tot_step: 47490, score: 29.0\n",
      "Run: 2111, tot_step: 47505, score: 15.0\n",
      "Run: 2112, tot_step: 47518, score: 13.0\n",
      "Run: 2113, tot_step: 47545, score: 27.0\n",
      "Run: 2114, tot_step: 47558, score: 13.0\n",
      "Run: 2115, tot_step: 47583, score: 25.0\n",
      "Run: 2116, tot_step: 47619, score: 36.0\n",
      "Run: 2117, tot_step: 47650, score: 31.0\n",
      "Run: 2118, tot_step: 47662, score: 12.0\n",
      "Run: 2119, tot_step: 47674, score: 12.0\n",
      "Run: 2120, tot_step: 47702, score: 28.0\n",
      "Run: 2121, tot_step: 47719, score: 17.0\n",
      "Run: 2122, tot_step: 47728, score: 9.0\n",
      "Run: 2123, tot_step: 47754, score: 26.0\n",
      "Run: 2124, tot_step: 47787, score: 33.0\n",
      "Run: 2125, tot_step: 47816, score: 29.0\n",
      "Run: 2126, tot_step: 47853, score: 37.0\n",
      "Run: 2127, tot_step: 47876, score: 23.0\n",
      "Run: 2128, tot_step: 47890, score: 14.0\n",
      "Run: 2129, tot_step: 47927, score: 37.0\n",
      "Run: 2130, tot_step: 47958, score: 31.0\n",
      "Run: 2131, tot_step: 47982, score: 24.0\n",
      "Run: 2132, tot_step: 48005, score: 23.0\n",
      "Run: 2133, tot_step: 48032, score: 27.0\n",
      "Run: 2134, tot_step: 48046, score: 14.0\n",
      "Run: 2135, tot_step: 48058, score: 12.0\n",
      "Run: 2136, tot_step: 48079, score: 21.0\n",
      "Run: 2137, tot_step: 48089, score: 10.0\n",
      "Run: 2138, tot_step: 48112, score: 23.0\n",
      "Run: 2139, tot_step: 48135, score: 23.0\n",
      "Run: 2140, tot_step: 48163, score: 28.0\n",
      "Run: 2141, tot_step: 48179, score: 16.0\n",
      "Run: 2142, tot_step: 48192, score: 13.0\n",
      "Run: 2143, tot_step: 48217, score: 25.0\n",
      "Run: 2144, tot_step: 48228, score: 11.0\n",
      "Run: 2145, tot_step: 48242, score: 14.0\n",
      "Run: 2146, tot_step: 48266, score: 24.0\n",
      "Run: 2147, tot_step: 48284, score: 18.0\n",
      "Run: 2148, tot_step: 48313, score: 29.0\n",
      "Run: 2149, tot_step: 48359, score: 46.0\n",
      "Run: 2150, tot_step: 48383, score: 24.0\n",
      "Run: 2151, tot_step: 48420, score: 37.0\n",
      "Run: 2152, tot_step: 48462, score: 42.0\n",
      "Run: 2153, tot_step: 48503, score: 41.0\n",
      "Run: 2154, tot_step: 48515, score: 12.0\n",
      "Run: 2155, tot_step: 48551, score: 36.0\n",
      "Run: 2156, tot_step: 48566, score: 15.0\n",
      "Run: 2157, tot_step: 48578, score: 12.0\n",
      "Run: 2158, tot_step: 48595, score: 17.0\n",
      "Run: 2159, tot_step: 48613, score: 18.0\n",
      "Run: 2160, tot_step: 48625, score: 12.0\n",
      "Run: 2161, tot_step: 48640, score: 15.0\n",
      "Run: 2162, tot_step: 48669, score: 29.0\n",
      "Run: 2163, tot_step: 48688, score: 19.0\n",
      "Run: 2164, tot_step: 48714, score: 26.0\n",
      "Run: 2165, tot_step: 48726, score: 12.0\n",
      "Run: 2166, tot_step: 48759, score: 33.0\n",
      "Run: 2167, tot_step: 48775, score: 16.0\n",
      "Run: 2168, tot_step: 48795, score: 20.0\n",
      "Run: 2169, tot_step: 48808, score: 13.0\n",
      "Run: 2170, tot_step: 48832, score: 24.0\n",
      "Run: 2171, tot_step: 48843, score: 11.0\n",
      "Run: 2172, tot_step: 48874, score: 31.0\n",
      "Run: 2173, tot_step: 48888, score: 14.0\n",
      "Run: 2174, tot_step: 48914, score: 26.0\n",
      "Run: 2175, tot_step: 48932, score: 18.0\n",
      "Run: 2176, tot_step: 48975, score: 43.0\n",
      "Run: 2177, tot_step: 49012, score: 37.0\n",
      "Run: 2178, tot_step: 49057, score: 45.0\n",
      "Run: 2179, tot_step: 49077, score: 20.0\n",
      "Run: 2180, tot_step: 49105, score: 28.0\n",
      "Run: 2181, tot_step: 49114, score: 9.0\n",
      "Run: 2182, tot_step: 49139, score: 25.0\n",
      "Run: 2183, tot_step: 49151, score: 12.0\n",
      "Run: 2184, tot_step: 49171, score: 20.0\n",
      "Run: 2185, tot_step: 49185, score: 14.0\n",
      "Run: 2186, tot_step: 49199, score: 14.0\n",
      "Run: 2187, tot_step: 49217, score: 18.0\n",
      "Run: 2188, tot_step: 49248, score: 31.0\n",
      "Run: 2189, tot_step: 49276, score: 28.0\n",
      "Run: 2190, tot_step: 49291, score: 15.0\n",
      "Run: 2191, tot_step: 49308, score: 17.0\n",
      "Run: 2192, tot_step: 49331, score: 23.0\n",
      "Run: 2193, tot_step: 49353, score: 22.0\n",
      "Run: 2194, tot_step: 49363, score: 10.0\n",
      "Run: 2195, tot_step: 49378, score: 15.0\n",
      "Run: 2196, tot_step: 49406, score: 28.0\n",
      "Run: 2197, tot_step: 49423, score: 17.0\n",
      "Run: 2198, tot_step: 49434, score: 11.0\n",
      "Run: 2199, tot_step: 49451, score: 17.0\n",
      "Run: 2200, tot_step: 49472, score: 21.0\n",
      "Run: 2201, tot_step: 49482, score: 10.0\n",
      "Run: 2202, tot_step: 49495, score: 13.0\n",
      "Run: 2203, tot_step: 49517, score: 22.0\n",
      "Run: 2204, tot_step: 49535, score: 18.0\n",
      "Run: 2205, tot_step: 49546, score: 11.0\n",
      "Run: 2206, tot_step: 49567, score: 21.0\n",
      "Run: 2207, tot_step: 49578, score: 11.0\n",
      "Run: 2208, tot_step: 49596, score: 18.0\n",
      "Run: 2209, tot_step: 49608, score: 12.0\n",
      "Run: 2210, tot_step: 49640, score: 32.0\n",
      "Run: 2211, tot_step: 49656, score: 16.0\n",
      "Run: 2212, tot_step: 49675, score: 19.0\n",
      "Run: 2213, tot_step: 49686, score: 11.0\n",
      "Run: 2214, tot_step: 49708, score: 22.0\n",
      "Run: 2215, tot_step: 49725, score: 17.0\n",
      "Run: 2216, tot_step: 49744, score: 19.0\n",
      "Run: 2217, tot_step: 49759, score: 15.0\n",
      "Run: 2218, tot_step: 49774, score: 15.0\n",
      "Run: 2219, tot_step: 49793, score: 19.0\n",
      "Run: 2220, tot_step: 49802, score: 9.0\n",
      "Run: 2221, tot_step: 49815, score: 13.0\n",
      "Run: 2222, tot_step: 49840, score: 25.0\n",
      "Run: 2223, tot_step: 49854, score: 14.0\n",
      "Run: 2224, tot_step: 49868, score: 14.0\n",
      "Run: 2225, tot_step: 49894, score: 26.0\n",
      "Run: 2226, tot_step: 49925, score: 31.0\n",
      "Run: 2227, tot_step: 49939, score: 14.0\n",
      "Run: 2228, tot_step: 49950, score: 11.0\n",
      "Run: 2229, tot_step: 49962, score: 12.0\n",
      "Run: 2230, tot_step: 49975, score: 13.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_52_input to have 4 dimensions, but got array with shape (1, 224, 256)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-e4d04992e9bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcartpole2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m400000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-96ed6701072d>\u001b[0m in \u001b[0;36mcartpole2\u001b[1;34m(EPISODES, STEP_MAX, render)\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[0mcurrent_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             \u001b[0mgame_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mterminal\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-727b721984c3>\u001b[0m in \u001b[0;36mstep_update\u001b[1;34m(self, total_step)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtotal_step\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mTRAINING_FREQUENCY\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage_max_q\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-727b721984c3>\u001b[0m in \u001b[0;36m_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    196\u001b[0m             \u001b[0mcurrent_states\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[0mnext_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"next_state\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m             \u001b[0mnext_state_prediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mddqn_target\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m             \u001b[0mnext_q_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_state_prediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m             \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mddqn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1440\u001b[0m         \u001b[1;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1441\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1442\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1443\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m         \u001b[1;31m# Standardize the inputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 574\u001b[1;33m         x = training_utils.standardize_input_data(\n\u001b[0m\u001b[0;32m    575\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m             \u001b[0mfeed_input_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    129\u001b[0m                 \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m                     raise ValueError(\n\u001b[0m\u001b[0;32m    132\u001b[0m                         \u001b[1;34m'Error when checking '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mexception_prefix\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected conv2d_52_input to have 4 dimensions, but got array with shape (1, 224, 256)"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import gym\n",
    "import random\n",
    "\n",
    "results = cartpole2(4000,400000,render=False)\n",
    "import matplotlib.pyplot as plt\n",
    "print(results)\n",
    "plt.plot(results)\n",
    "plt.savefig('score_ddqn.png', bbox_inches='tight')\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "im = imageio.imread('fake.png')\n",
    "im=np.dot(im[...,:3], [0.299, 0.587, 0.114])\n",
    "print(im[205])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
